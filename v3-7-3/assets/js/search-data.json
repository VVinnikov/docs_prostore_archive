{"0": {
    "doc": "docs_prostore",
    "title": "docs_prostore",
    "content": "Prostore user guide . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/README.html",
    "relUrl": "/README.html"
  },"1": {
    "doc": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "title": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "content": "Запрос позволяет перезапустить отмену неуспешных операций записи. При ошибке загрузки данных система автоматически отменяет неуспешную операцию записи и возвращает данные СУБД хранилища в состояние, которое предшествовало загрузке. Однако, если при откате неуспешной операции записи произошла ошибка (например, из-за неполадок в сети или СУБД), система возвращает исключение и запись не отменяется. В этом случае необходимо устранить причины ошибки и вручную перезапустить отмену неуспешных операций записей. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. После выполнения запроса необходимо вызвать ROLLBACK DELTA. В ответе возвращается: . | объект ResultSet с пустой записью, если неуспешные операции записи отсутствуют; | объект ResultSet c записями, каждая из которых содержит имя логической таблицы в столбце table_name и номер отмененной операции записи в столбце sys_cn_operations. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html"
  },"2": {
    "doc": "ROLLBACK CRASHED_WRITE_OPERATIONS",
    "title": "Синтаксис",
    "content": "ROLLBACK CRASHED_WRITE_OPERATIONS . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html#синтаксис",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/ROLLBACK_CRASHED_WRITE_OPERATIONS/ROLLBACK_CRASHED_WRITE_OPERATIONS.html#синтаксис"
  },"3": {
    "doc": "Обзор понятий, компонентов и связей",
    "title": "Обзор понятий, компонентов и связей",
    "content": "Обзор понятий, компонентов и связей . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Обзор_понятий_компонентов_и_связей.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Обзор_понятий_компонентов_и_связей.html"
  },"4": {
    "doc": "Введение",
    "title": "Введение",
    "content": "Введение . DTM (далее — система) — система для построения витрин данных, позволяющая работать как с актуальными, так и архивными данными. Система выполняет роль интеграционного сервиса, объединяющего различные СУБД хранилища, и предоставляет следующие возможности: . | работа с данными с использованием единой логической схемы данных, не зависящей от типа СУБД хранилища; | параллельная загрузка и выгрузка больших объемов данных; | запрос и выгрузка данных, актуальных по состоянию на указанный момент времени; | частичное или полное удаление истории изменений данных. | . Работа с системой возможна с помощью любых программных инструментов, которые предоставляют подключение через JDBC-интерфейс. Для запросов к системе используется декларативный язык запросов на основе SQL, в некоторых случаях совпадающий с SQL-стандартом (см. Запросы SQL ). ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Введение/Введение.html",
    "relUrl": "/Введение/Введение.html"
  },"5": {
    "doc": "Поддерживаемые СУБД хранилища",
    "title": "Поддерживаемые СУБД хранилища",
    "content": "Поддерживаемые СУБД хранилища . Система поддерживает работу со следующими СУБД хранилища: . | Arenadata DB (ADB) — СУБД с массивно-параллельной архитектурой (Massive parallel processing, MPP), построенная на основе Greenplum; | Arenadata QuickMarts (ADQM) — кластерная колоночная СУБД на основе Yandex ClickHouse; | Arenadata Grid (ADG) — система распределенных вычислений в оперативной памяти, построенная на основе Tarantool. | . Система позволяет работать с перечисленными СУБД одинаковым образом, используя единый синтаксис запросов SQL и единую логическую схему данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Введение/Поддерживаемые_СУБД_хранилища/Поддерживаемые_СУБД_хранилища.html",
    "relUrl": "/Введение/Поддерживаемые_СУБД_хранилища/Поддерживаемые_СУБД_хранилища.html"
  },"6": {
    "doc": "Термины и определения",
    "title": "Термины и определения",
    "content": "Термины и определения . Система — система DTM, описываемая в данном документе. Внешняя информационная система — внешняя система, которая является источником загружаемых данных и (или) получателем выгружаемых данных. СУБД — СУБД из числа поддерживаемых системой. СУБД выгрузки данных — СУБД, из которой выгружаются данные системы. СУБД выгрузки данных определяется в конфигурации системы. Фиксация изменений в данных — процесс сохранения состояния витрины данных, запускаемый соответствующей командой после загрузки данных в систему. Горячая запись — запись, которая загружена в систему, но еще не зафиксирована. После фиксации изменений горячая запись переходит в категорию актуальных. Актуальная запись — зафиксированная запись, которая является актуальной на данный момент. Архивная запись — зафиксированная запись, которая больше не является актуальной. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Введение/Термины_и_определения/Термины_и_определения.html",
    "relUrl": "/Введение/Термины_и_определения/Термины_и_определения.html"
  },"7": {
    "doc": "Компоненты системы",
    "title": "Компоненты системы",
    "content": "Компоненты системы . Система состоит из следующих компонентов (см. рисунок ниже): . | JDBC-драйвер — размещается на стороне внешней информационной системы; предоставляет JDBC-интерфейс подключения к DTM и взаимодействует с сервисом исполнения запросов по REST API; | сервис исполнения запросов (DTM Core) — анализирует и исполняет SQL-запросы; предоставляет REST API для JDBC-драйвера и взаимодействует с сервисом мониторинга статусов Kafka по REST API; | сервис мониторинга статусов Kafka (DTM Status Monitor) — отслеживает состояние топиков брокера сообщений Kafka; предоставляет REST API для сервиса исполнения запросов. | . Версии используемых компонентов системы можно проверить с помощью запроса CHECK_VERSIONS. На рисунке ниже показана схема компонентов системы. Компоненты системы . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Компоненты_системы/Компоненты_системы.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Компоненты_системы/Компоненты_системы.html"
  },"8": {
    "doc": "Внешняя таблица",
    "title": "Внешняя таблица",
    "content": "Внешняя таблица . Внешняя таблица задает набор параметров внешнего приемника данных (например, топика Kafka), используемого для параллельной загрузки или выгрузки данных. Набор включает следующие параметры: . | список передаваемых полей, | путь к внешнему приемнику данных, | формат обмена данными. | . Внешняя таблица представляет собой декларацию источника/приемника данных и формата загрузки/выгрузки данных и не хранит сами данные. Внешние таблицы разделяются по назначению: . | внешние таблицы загрузки используются для загрузки данных в систему, | внешние таблицы выгрузки используются для выгрузки данных из системы. | . Внешние таблицы можно создавать и удалять: . | Создание внешней таблицы загрузки, | Создание внешней таблицы выгрузки, | Удаление внешней таблицы загрузки, | Удаление внешней таблицы выгрузки. | . В зависимости от требований проекта созданная внешняя таблица может использоваться однократно или многократно. Следует учитывать, что потоки обмена данными с системой должны быть разделены по приемникам данных в следующих разрезах: . | по логическим таблицам, | по направлениям передачи данных (загрузка/выгрузка), | (опционально) на основе каких-либо дополнительных критериев (например, по целевым информационным системам). | . Например, если для логической таблицы транзакций нужно поддержать и загрузку, и выгрузку данных, следует создать две (или более) внешние таблицы: хотя бы одну таблицу загрузки транзакций и хотя бы одну — выгрузки. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Внешняя_таблица/Внешняя_таблица.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Внешняя_таблица/Внешняя_таблица.html"
  },"9": {
    "doc": "Дельта",
    "title": "Дельта",
    "content": "Дельта . Дельта — целостная совокупность изменений в логической базе данных. Дельта включает все операции записи, выполненные между открытием и закрытием этой дельты, и имеет порядковый номер, уникальный в рамках логической базы данных. Нумерация дельт начинается с 0. Дельты упорядочены в порядке возрастания их номеров и формируют историю состояний данных логической БД. На рисунке ниже показана последовательность операций записи, выполненных в рамках дельт с номерами 0 и 1. В рамках дельты 0 выполнены операции записи с номерами 0-2, в рамках дельты 1 — операции записи с номерами 3-6. Операции записи двух дельт . Дельту можно открыть, закрыть и отменить. Дельта, которая была открыта и еще не была закрыта, содержит горячие записи и называется открытой или горячей. Для каждой логической базы одновременно может быть открыто не более одной дельты. Дельта, которая была закрыта (зафиксирована) содержит актуальные записи и называется закрытой. На рисунке ниже показана последовательность дельт, где дельта с номером 3 является открытой, а все предыдущие — закрытыми. Открытая и закрытые дельты . Для загрузки данных в логическую БД нужно открыть дельту, загрузить данные в требуемые логические таблицы, после чего сохранить изменения (закрыть дельту). В рамках открытой дельты можно выполнить произвольное число операций записи. Примечание: не допускается загрузка различных состояний одного и того же объекта в рамках одной дельты. Для загрузки обновленных данных объекта нужно закрыть открытую дельту, открыть новую дельту и загрузить необходимые изменения (см. пример на рисунке ниже). На рисунке ниже показан пример обновления данных клиента, сменившего фамилию. Первоначальные данные клиента загружены в рамках дельты 0, а обновленные данные — в рамках дельты 1. Обновление данных клиента, сменившего фамилию . Если нужно вернуть состояние данных, которое предшествовало изменениям, выполненным в рамках открытой дельты, следует откатить дельту. Откат дельты возможен только для открытой дельты, после закрытия дельты возврат к предыдущему состоянию недоступен. При запросе и выгрузке данных номер дельты можно использовать, чтобы указать момент или период, по состоянию на который запрашивается информация (см. директиву FOR SYSTEM_TIME в разделе SELECT). ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Дельта/Дельта.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Дельта/Дельта.html"
  },"10": {
    "doc": "Логическая база данных",
    "title": "Логическая база данных",
    "content": "Логическая база данных . Логическая база данных (логическая БД) — совокупность логических сущностей (логических таблиц, логических представлений и внешних таблиц), сгруппированных по какому-либо принципу, например по направлению анализа. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_база_данных/Логическая_база_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_база_данных/Логическая_база_данных.html"
  },"11": {
    "doc": "Логическая схема данных",
    "title": "Логическая схема данных",
    "content": "Логическая схема данных . Логическая схема данных — внешнее представление структуры данных окружения, единое для всех поддерживаемых СУБД хранилища. Логическая схема данных представляет собой иерархию следующих объектов: . | логических баз данных, | логических таблиц, | логических представлений, | внешних таблиц. | . Логическая схема данных хранится в сервисной базе данных системы. На рисунке ниже показана иерархия объектов логической схемы данных. Объекты логической схемы и их связи с объектами физической схемы . Внешняя информационная система (пользователь) отправляет системе запросы к данным, сформулированные в терминах логической схемы. Система разбирает полученные запросы, модифицирует их нужным образом и перенаправляет к физическим таблицам хранилища данных. В зависимости от момента времени, указанного в запросе, система обращается к актуальным или архивным данным. Такая модель взаимодействия позволяет работать с различными версиями данных, которые хранятся в различных СУБД хранилища, в едином формате. Связанные разделы: . | Управление схемой данных. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_схема_данных/Логическая_схема_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_схема_данных/Логическая_схема_данных.html"
  },"12": {
    "doc": "Логическая таблица",
    "title": "Логическая таблица",
    "content": "Логическая таблица . Логическая таблица — структурированная совокупность записей о состояниях объектов одного типа, например счетов или контрагентов. Логическая таблица не хранит сами данные, а предоставляет доступ к данным соответствующих физических таблиц хранилища. В отличие от реляционной таблицы, объекты которой обычно хранятся в актуальном (текущем) состоянии, логическая таблица предоставляет информацию обо всех исторических состояниях объектов: новых, актуальных и архивных. Например, данные одного клиента могут иметь нескольких версий в логической таблице clients: . | архивная запись с номером телефона phone_1 и адресом address_1, | актуальная запись с номером телефона phone_2 и адресом address_1 (клиент сменил номер телефона), | горячая (новая) запись с номером телефона phone_2 и адресом address_2 (клиент сменил адрес; запись загружена, но еще не зафиксирована). | . На рисунке ниже показана схема связей логической таблицы с ее физическими представлениями — физическими таблицами хранилища данных. Связи логической таблицы с физическими таблицами . Работа с логическими таблицами напоминает работу с реляционными таблицами. Логические таблицы можно создавать и удалять. Данные логической таблицы можно загружать, запрашивать и выгружать. При обращении к данным логической таблицы можно указать момент времени, по состоянию на который запрашиваются данные. Если момент времени не указан, система возвращает данные, актуальные на момент обработки запроса. Таким образом, можно получать данные из логической таблицы по состоянию на любой момент времени — независимо от того, являются они горячими (новыми), актуальными или архивными. При создании логической таблицы система автоматически создает и далее поддерживает набор физических таблиц для хранения данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_таблица/Логическая_таблица.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическая_таблица/Логическая_таблица.html"
  },"13": {
    "doc": "Логическое представление",
    "title": "Логическое представление",
    "content": "Логическое представление . Логическое представление — сохраненный запрос к данным одной или нескольких логических таблиц, который имеет имя и может использоваться как источник данных в других запросах. Примером логического представления является список контрагентов, объединенный с информацией о благонадежности контрагентов и их контактами. Работа с логическими представлениями напоминает работу с реляционными представлениями. Логические представления можно создавать, изменять и удалять. Данные логического представления можно запрашивать и выгружать. Логическое представление проецирует данные связанных логических таблиц и не отражается в хранилище. Загрузка данных в логические представления невозможна. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическое_представление/Логическое_представление.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Логическое_представление/Логическое_представление.html"
  },"14": {
    "doc": "Окружение",
    "title": "Окружение",
    "content": "Окружение . Окружение — совокупность логических баз данных, доступных при работе с системой. Инсталляция системы работает с окружением, заданным в ее конфигурации. Допустимо создавать несколько окружений для одного набора кластеров СУБД и при необходимости перенастраивать инсталляцию системы на другое окружение. Попеременное использование независимых окружений может быть полезно, например, в случае разделения различных тестовых сред. На рисунке ниже показан пример инсталляции системы с тремя окружениями, где в настоящий момент внешняя информационная система работает с окружением test2. Инсталляция системы с тремя окружениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Окружение/Окружение.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Окружение/Окружение.html"
  },"15": {
    "doc": "Операция записи",
    "title": "Операция записи",
    "content": "Операция записи . Операция записи — операция загрузки нового состояния объектов из внешнего источника в логическую таблицу. В рамках дельты можно выполнить произвольное количество операций записи. Каждая операция записи имеет порядковый номер, уникальный среди всех операций записи в логической базе данных. Нумерация начинается с 0. Номера операций записи используются в физических таблицах для обозначения границ периода [sys_from, sys_to], в котором запись была актуальна. На рисунке ниже показан пример с тремя операциями записи (0, 1, 2) в двух логических таблицах: clients и sales. В этом примере операции 0 и 2 выполнены по отдельности, однако их изменения могли быть загружены в таблицу clients в рамках одной операции записи. Операции записи в двух логических таблицах . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Операция_записи/Операция_записи.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Операция_записи/Операция_записи.html"
  },"16": {
    "doc": "Основные понятия",
    "title": "Основные понятия",
    "content": "Основные понятия . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Основные_понятия.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Основные_понятия.html"
  },"17": {
    "doc": "Сервисная база данных",
    "title": "Сервисная база данных",
    "content": "Сервисная база данных . Сервисная база данных — сервис, используемый ядром системы для хранения метаданных, в частности логической схемы данных и информации о дельтах. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Сервисная_база_данных/Сервисная_база_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Сервисная_база_данных/Сервисная_база_данных.html"
  },"18": {
    "doc": "Физическая схема данных",
    "title": "Физическая схема данных",
    "content": "Физическая схема данных . Физическая схема данных — структура хранения данных в хранилище, создаваемая и поддерживаемая системой. Для каждой логической таблицы система создает и поддерживает набор физических таблиц, перечисленных в таблице ниже. Состав набора физических таблиц зависит от типа СУБД хранилища. | Физическая таблица | ADB | ADG | ADQM | . | &lt;table&gt;_staging | Горячие записи | Горячие записи | − | . | tbl_buffer | − | − | Идентификаторы горячих записей | . | &lt;table&gt;_actual | Актуальные и архивные записи | Актуальные записи | Горячие, актуальные и архивные записи всех узлов кластера | . | &lt;table&gt;_history | − | Архивные записи | − | . | &lt;table&gt;_actual_shard | − | − | Горячие, актуальные и архивные записи узла кластера | . | tbl_buffer_shard | − | − | Идентификаторы горячих записей узла кластера | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Физическая_схема_данных/Физическая_схема_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Физическая_схема_данных/Физическая_схема_данных.html"
  },"19": {
    "doc": "Физическая таблица",
    "title": "Физическая таблица",
    "content": "Физическая таблица . Физическая таблица — таблица СУБД хранилища, каждая запись которой описывает состояние объекта логической таблицы в определенный период времени. В зависимости от типа физической таблицы состояние объектов, хранящееся в ней, может быть новым (“горячим”), актуальным или архивным. Все данные, загруженные в систему, до фиксации изменений считаются новым состоянием объектов и хранятся в виде горячих записей. При фиксации изменений система одномоментно обновляет состояние объектов, исключая возможность чтения грязных данных. Обновление происходит в следующем порядке: . | Сравниваются новое и актуальное состояния объектов. | Определяется, какие записи нужно добавить (если таких объектов нет среди актуальных данных), а какие — заменить новыми (если объекты уже есть в системе, и нужно обновить их состояние). | Состояние новых объектов фиксируется в виде актуальных записей. | Для существующих объектов записи, которые считались актуальными до момента фиксации изменений, перемещаются в категорию архивных, а новое состояние объектов фиксируется в виде актуальных записей. | Все горячие записи удаляются. | В историю изменений состояния системы добавляется новая дельта с номером, увеличенным на 1 относительно предыдущей зафиксированной дельты. | . На рисунке ниже показан пример обновления состояния объекта — набора данных одного клиента. В примере рассматривается следующая ситуация: номер телефона клиента был ранее изменен со значения phone_1 на phone_2, это изменение было зафиксировано, и теперь загружаются данные того же клиента с новым адресом (address_2). Обновление данных клиента . В условиях, рассмотренных в примере, данные клиента обновляются в следующем порядке: . | Загрузка данных: запись с новым адресом (address_2) сохраняется в качестве горячей записи. | Фиксация изменений данных: запись с предыдущим адресом (address_1) переносится в категорию архивных, запись с новым адресом (address_2) — в категорию актуальных, и горячая запись удаляется. Обновление записей происходит одномоментно. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Физическая_таблица/Физическая_таблица.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Физическая_таблица/Физическая_таблица.html"
  },"20": {
    "doc": "Хранилище данных",
    "title": "Хранилище данных",
    "content": "Хранилище данных . Физическое хранилище данных (далее — хранилище) — совокупность СУБД различного типа, в которых хранятся данные логических таблиц. Данные в хранилище хранятся в соответствии с физической схемой данных. Система предоставляет единый интерфейс взаимодействия с хранилищем в виде логической базы данных. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Основные_понятия/Хранилище_данных/Хранилище_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Основные_понятия/Хранилище_данных/Хранилище_данных.html"
  },"21": {
    "doc": "Порядок обработки запросов на выгрузку данных",
    "title": "Порядок обработки запросов на выгрузку данных",
    "content": "Порядок обработки запросов на выгрузку данных . Запрос на выгрузку данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO download_external_table, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов на основании конфигурации определяет, для какой СУБД хранилища данных предназначен запрос, и отправляет в соответствующий коннектор команду на выгрузку данных из этой СУБД. | Коннектор выгружает данные в топик Kafka, который определен в свойствах внешней таблицы выгрузки, указанной в запросе. | После успешного выполнения выгрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_выгрузку_данных/Порядок_обработки_запросов_на_выгрузку_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_выгрузку_данных/Порядок_обработки_запросов_на_выгрузку_данных.html"
  },"22": {
    "doc": "Порядок обработки запросов на загрузку данных",
    "title": "Порядок обработки запросов на загрузку данных",
    "content": "Порядок обработки запросов на загрузку данных . Запрос на загрузку данных в логическую таблицу обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос INSERT INTO logical_table, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и сохраняет информацию о процессе загрузки данных в сервисной базе данных. | Сервис исполнения запросов отправляет в коннектор каждой из целевых СУБД хранилища команду на загрузку данных и отслеживает состояние загрузки с помощью сервиса мониторинга статусов Kafka. Под целевыми подразумеваются СУБД, в которых размещаются данные логической таблицы (см. CREATE TABLE). | Коннектор загружает данные из топика Kafka, который определен в свойствах внешней таблицы загрузки, указанной в запросе. | По завершении загрузки всех или каждого пакета данных (в зависимости от типа СУБД) сервис исполнения запросов отправляет в целевые СУБД команду на выполнение задач по версионированию данных. | После успешного выполнения загрузки данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_загрузку_данных/Порядок_обработки_запросов_на_загрузку_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_загрузку_данных/Порядок_обработки_запросов_на_загрузку_данных.html"
  },"23": {
    "doc": "Порядок обработки запросов на обновление логической схемы",
    "title": "Порядок обработки запросов на обновление логической схемы",
    "content": "Порядок обработки запросов на обновление логической схемы . Запрос на обновление логической схемы данных обрабатывается в следующем порядке: . | Внешняя информационная система формирует запрос на обновление логической схемы данных, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов определяет, для каких СУБД хранилища предназначен запрос, модифицирует запрос нужным образом и отправляет в соответствующие СУБД команду на обновление физической схемы данных. | Сервис исполнения запросов сохраняет изменения логической схемы данных в сервисной базе данных. | Сервис исполнения запросов публикует сообщение об обновлении логической схемы данных в топике Kafka, указанном в конфигурации системы (см. параметр KAFKA_STATUS_EVENT_TOPIC). | После успешного обновления логической и физической схем данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_обновление_логической_схемы/Порядок_обработки_запросов_на_обновление_логической_схемы.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_обновление_логической_схемы/Порядок_обработки_запросов_на_обновление_логической_схемы.html"
  },"24": {
    "doc": "Порядок обработки запросов на чтение данных",
    "title": "Порядок обработки запросов на чтение данных",
    "content": "Порядок обработки запросов на чтение данных . Запросы на чтение данных обрабатываются в следующем порядке: . | Внешняя информационная система формирует запрос, используя JDBC-драйвер DTM. | Запрос поступает в сервис исполнения запросов DTM. | Сервис исполнения запросов анализирует запрос и запрашивает актуальную информацию о логической схеме данных в сервисной базе данных. | Сервис исполнения запросов определяет, для какой СУБД хранилища данных предназначен запрос, модифицирует запрос нужным образом и отправляет в эту СУБД команду на исполнение модифицированного запроса. | После успешного выполнения чтения данных JDBC-драйвер возвращает синхронный ответ во внешнюю информационную систему. | . Подробнее о компонентах системы см. в разделе Компоненты системы, обо всех внешних связях системы см. в разделе Связи с другими системами и компонентами. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_чтение_данных/Порядок_обработки_запросов_на_чтение_данных.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Порядок_обработки_запросов_на_чтение_данных/Порядок_обработки_запросов_на_чтение_данных.html"
  },"25": {
    "doc": "Связи с другими системами и компонентами",
    "title": "Связи с другими системами и компонентами",
    "content": "Связи с другими системами и компонентами . Система взаимодействует со следующими внешними системами и компонентами (см. рисунок ниже): . | внешней информационной системой-клиентом (по JDBC-интерфейсу), | сервисной базой данных (по API ZooKeeper), | СУБД хранилища данных (по интерфейсу JDBC или REST API — в зависимости от типа СУБД), | коннекторами (по API коннекторов); | брокером сообщений Kafka (по API Kafka). | . На рисунке ниже показаны взаимодействия системы с внешними системами и компонентами. Внешние взаимодействия системы . Взаимодействия системы с внешними системами и компонентами при выполнении основных действий описаны в разделах: . | Порядок обработки запросов на обновление логической схемы | Порядок обработки запросов на загрузку данных | Порядок обработки запросов на выгрузку данных | Порядок обработки запросов на чтение данных | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Связи_с_другими_системами_и_компонентами.html",
    "relUrl": "/Обзор_понятий_компонентов_и_связей/Связи_с_другими_системами_и_компонентами/Связи_с_другими_системами_и_компонентами.html"
  },"26": {
    "doc": "Выгрузка данных",
    "title": "Выгрузка данных",
    "content": "Выгрузка данных . Система позволяет выгружать актуальные и архивные данные, а также совокупность изменений, выполненных в рамках указанных дельт. Возможные способы выборки выгружаемых данных описаны в секции FOR SYSTEM_TIME раздела SELECT. Для выгрузки данных нужен существующий топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе необходимо создать топик, если он еще не создан. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Чтобы выгрузить данные из логической таблицы или логического представления во внешнюю информационную систему: . | Создайте внешнюю таблицу выгрузки, если она еще не создана. | Выполните запрос INSERT INTO download_external_table на выгрузку данных в топик. В запросе нужно указать внешнюю таблицу выгрузки, определяющую параметры выгрузки. | Выгрузите данные из топика во внешнюю информационную систему. | . Созданные внешние таблицы выгрузки можно использовать повторно или удалить. Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- создание внешней таблицы выгрузки CREATE DOWNLOAD EXTERNAL TABLE sales_ext_download ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 -- запуск выгрузки данных из логической таблицы sales INSERT INTO sales_ext_download SELECT * FROM sales WHERE product_units &gt; 2 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Выгрузка_данных/Выгрузка_данных.html",
    "relUrl": "/Работа_с_системой/Выгрузка_данных/Выгрузка_данных.html"
  },"27": {
    "doc": "Другие функции",
    "title": "Другие функции",
    "content": "Другие функции . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Другие_функции/Другие_функции.html",
    "relUrl": "/Работа_с_системой/Другие_функции/Другие_функции.html"
  },"28": {
    "doc": "Определение логической БД по умолчанию",
    "title": "Определение логической БД по умолчанию",
    "content": "Определение логической БД по умолчанию . Логическую базу данных можно определить как используемую по умолчанию. Если логическая база данных по умолчанию определена, система использует ее имя всякий раз, когда в запросах явно не указана логическая БД. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. Чтобы определить логическую базу данных по умолчанию, используйте любой из способов: . | Укажите логическую базу данных в настройках JDBC-подключения к системе (см. рисунок ниже). Логическая база данных указывается последним параметром адресной строки (например, jdbc:adtm://10.92.3.3:9092/sales, где sales — имя логической базы данных). Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или изменение настроек JDBC-подключения. | Выполните запрос USE. Логическая база, указанная таким образом, используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. | . На рисунке ниже показан пример настройки параметров JDBC-подключения в SQL-клиенте, где логическая БД sales указана как используемая по умолчанию. Параметры JDBC-драйвера с указанной логической БД по умолчанию . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Другие_функции/Определение_логической_БД_по_умолчанию/Определение_логической_БД_по_умолчанию.html",
    "relUrl": "/Работа_с_системой/Другие_функции/Определение_логической_БД_по_умолчанию/Определение_логической_БД_по_умолчанию.html"
  },"29": {
    "doc": "Версионирование данных",
    "title": "Версионирование данных",
    "content": "Версионирование данных . Все записи логической таблицы с одинаковым первичным ключом рассматриваются системой как исторические состояния одного и того же объекта. Одновременно объект системы может иметь множество архивных состояний, а также не более одного актуального и не более одного нового (“горячего”) состояния. Записи, загружаемые в логическую таблицу в рамках одной дельты, должны иметь уникальный первичный ключ. Для того чтобы система могла корректно определить, что делать с загруженными записями, каждая из них должна содержать значение sys_op. Поле sys_op является служебным и может принимать следующие значения: . | 0 — нужно добавить новую запись или обновить существующую, если такая будет найдена; | 1 — нужно удалить существующую запись. | . Если поле sys_op отсутствует в схеме данных Avro и (или) в загружаемых записях, при попытке выполнить запрос INSERT INTO logical_table система вернет исключение. Все загружаемые данные сохраняются в виде горячих записей, и затем, при фиксации изменений, система обновляет состояние объектов логических таблиц в соответствии с новыми данными. Порядок применения каждой из новых записей зависит от наличия/отсутствия актуальной записи с таким же первичным ключом и значения sys_op новой записи: . | Если актуальная запись есть и значение sys_op новой записи равно 0, актуальная запись перемещается в архив, а новая запись сохраняется в качестве актуальной. | Если актуальная запись есть и значение sys_op новой записи равно 1, актуальная запись перемещается в архив. Добавление новой записи не происходит, и среди актуальных записей не остается записей с этим первичным ключом. | Если актуальной записи нет, новая запись сохраняется в качестве актуальной. | . Примечание: для удаления записи нужно, чтобы все данные новой записи (кроме значения sys_op) совпадали с данными одной из актуальных записей логической таблицы. Если первичные ключи актуальной и новой записи совпадают, но другие данные этих записей различаются, выдается исключение и запись не удаляется. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Загрузка_данных/Версионирование_данных/Версионирование_данных.html",
    "relUrl": "/Работа_с_системой/Загрузка_данных/Версионирование_данных/Версионирование_данных.html"
  },"30": {
    "doc": "Загрузка данных",
    "title": "Загрузка данных",
    "content": "Загрузка данных . Для загрузки данных нужен существующий топик Kafka. Если в брокере сообщений Kafka настроено автоматическое создание топиков, то дополнительные действия не требуются. Иначе необходимо создать топик, если он еще не создан. Подробнее о создании топиков см. в документации Kafka: . | раздел Quick Start, | раздел Adding and removing topics. | . Чтобы загрузить данные из внешней информационной системы в логическую таблицу: . | Загрузите данные из внешней информационной системы в топик Kafka. Данные должны иметь формат, описанный в разделе Формат загрузки данных. | Создайте логическую таблицу, если она еще не создана. | Создайте внешнюю таблицу загрузки, если она еще не создана. | Выполните запрос BEGIN DELTA на открытие дельты, если она еще не открыта. | Выполните запрос INSERT INTO logical_table на загрузку данных из топика в логическую таблицу. В запросе нужно указать внешнюю таблицу загрузки, определяющую параметры загрузки. После успешного окончания загрузки данных система вернет ответ с пустым объектом ResultSet. | Если необходимо, загрузите другие данные, например в другие логические таблицы. В рамках одной открытой дельты можно выполнять произвольное количество запросов INSERT INTO logical_table, при этом не допускается загрузка различных состояний одного и того же объекта. | Выполните запрос COMMIT DELTA для сохранения изменений и закрытия дельты. | . При успешном выполнении последовательности действий загруженные данные сохраняются в качестве актуальных, а предыдущая версия данных, если такая была, становится архивной. Подробнее о версионировании см. в разделе Версионирование данных. Пока дельта не закрыта, все изменения данных, выполненные в рамках нее, можно отменить (см. ROLLBACK DELTA). Созданные внешние таблицы загрузки можно использовать повторно или удалить. Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- создание логической таблицы sales CREATE TABLE sales ( identification_number INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (identification_number) ) DISTRIBUTED BY (identification_number) -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 -- открытие новой (горячей) дельты BEGIN DELTA -- запуск загрузки данных в логическую таблицу sales INSERT INTO sales SELECT * FROM sales.sales_ext_upload -- закрытие дельты (фиксация изменений) COMMIT DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Загрузка_данных/Загрузка_данных.html",
    "relUrl": "/Работа_с_системой/Загрузка_данных/Загрузка_данных.html"
  },"31": {
    "doc": "Запрос данных",
    "title": "Запрос данных",
    "content": "Запрос данных . Система позволяет запрашивать небольшие объемы актуальных и архивных данных, а также изменений, выполненных в рамках указанных дельт. Возможные способы выборки данных описаны в секции FOR SYSTEM_TIME раздела SELECT. Чтобы запросить небольшой объем данных из логических таблиц и (или) представлений, выполните запрос SELECT. Запросы на чтение данных обрабатываются в порядке, описанном в разделе Порядок обработки запросов на чтение данных. При успешном выполнении запроса запрошенные данные возвращаются в ответе. Примечание: под небольшим объемом данных подразумевается результат, содержащий десятки строк. Для запроса большого объема данных следует использовать функцию выгрузки данных. На рисунке ниже показан пример запроса из логической таблицы sales, возвращающий одну строку. Так как секция DATASOURCE_TYPE не указана, система автоматически направляет запрос в СУБД, оптимальную для его исполнения (см. Маршрутизация запросов к данным). Запрос небольшого объема данных . Пример . -- выбор логической базы данных sales в качестве базы данных по умолчанию USE sales -- запрос данных из логической таблицы sales SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20 -- запрос данных из логического представления stores_by_sold_products SELECT sold.store_id, sold.product_amount FROM stores_by_sold_products AS sold . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Запрос_данных/Запрос_данных.html",
    "relUrl": "/Работа_с_системой/Запрос_данных/Запрос_данных.html"
  },"32": {
    "doc": "Маршрутизация запросов к данных",
    "title": "Маршрутизация запросов к данных",
    "content": "Маршрутизация запросов к данных . Запросы к данным маршрутизируются следующим образом: . | если в запросе указана СУБД хранилища (см. DATASOURCE_TYPE), в которой должен быть выполнен запрос, запрос направляется в указанную СУБД; | иначе запрос маршрутизируется автоматически на основе его категории в соответствии с конфигурацией системы. | . По умолчанию в конфигурации определен следующий порядок выбора СУБД для исполнения запросов: . | реляционные запросы — запросы с операторами JOIN и (или) подзапросами — направляются в ADB; | запросы агрегации и группировки данных направляются в ADQM; | запросы точечного чтения по ключу направляются в ADG; | запросы, не соответствующие ни одной из предыдущих категорий, направляются в ADB. | . Категория запроса определяется в указанном выше порядке. Например, если запрос содержит оператор JOIN, то он попадает в первую категорию независимо от наличия агрегации, группировки и чтения по ключу. Примеры запросов каждой из категорий см. ниже. Указанный порядок выбора СУБД эффективно использует возможности каждой из СУБД хранилища, однако при необходимости его можно изменить в конфигурации системы. Примечание: наиболее полный синтаксис запросов доступен в ADB. ADG и ADQM имеют ограничения на выполнение запросов, вызванные особенностями этих СУБД (см. Поддержка SQL). Примеры запросов различных категорий . Реляционный запрос: . SELECT * FROM sales.sales AS s JOIN sales.stores AS st ON s.store_id = st.identification_number . Реляционный запрос с агрегацией, группировкой и чтением по ключу (st.identification_number): . SELECT st.identification_number, st.category, SUM(s.product_units) AS product_amount FROM sales.stores AS st JOIN sales.sales AS s ON st.identification_number = s.store_id WHERE st.identification_number &lt;&gt; 10004 GROUP BY st.identification_number, st.category ORDER BY product_amount DESC . Запрос агрегации и группировки: . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY s.product_code ORDER BY product_amount ASC . Запрос агрегации и группировки с чтением по ключу (s.identification_number): . SELECT s.product_code, SUM(s.product_units) AS product_amount FROM sales.sales AS s WHERE s.identification_number &gt; 20000 GROUP BY s.product_code . Запрос чтения по ключу: . SELECT * FROM sales.sales as s WHERE s.identification_number BETWEEN 1001 AND 2000 . Запрос неопределенной категории: . SELECT * FROM sales.sales AS s WHERE s.product_units &gt; 2 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Запрос_данных/Маршрутизация_запросов_к_данным/Маршрутизация_запросов_к_данным.html",
    "relUrl": "/Работа_с_системой/Запрос_данных/Маршрутизация_запросов_к_данным/Маршрутизация_запросов_к_данным.html"
  },"33": {
    "doc": "Подключение",
    "title": "Подключение",
    "content": "Подключение . Чтобы начать работать с системой, нужно подключиться к системе. Доступны следующие способы подключения: . | с помощью SQL-клиента, например DBeaver или DataGrip; | с помощью программного подключения. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Подключение/Подключение.html",
    "relUrl": "/Работа_с_системой/Подключение/Подключение.html"
  },"34": {
    "doc": "Подключение с помощью SQL-клиента",
    "title": "Подключение с помощью SQL-клиента",
    "content": "Подключение с помощью SQL-клиента . Перед настройкой подключения загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar в вашу файловую систему. Чтобы настроить подключение к системе с помощью SQL-клиента: . | Откройте меню, отвечающее за добавление новых JDBC-драйверов. В SQL-клиенте DBeaver это меню Driver Management, доступное в панели Database Navigator, в DataGrip — меню Data Sources. | Добавьте новый драйвер со следующими настройками (см. рисунок ниже): (Driver) Name — произвольное имя драйвера, например DTM, (Class) Name — io.arenadata.dtm.jdbc.DtmDriver, URL Template — jdbc:adtm://{host}:{port}/{database}, Default Port (если параметр присутствует) — 9090 или 9092. | Нажмите кнопку Add (File) для добавления файла драйвера и выберите файл dtm-jdbc-&lt;version&gt;.jar в вашей файловой системе. | Сохраните настройки драйвера. | Настройте новое подключение к системе с использованием добавленного JDBC-драйвера и укажите URL для подключения (например, jdbc:adtm://10.92.3.3:9092). | . После завершения настройки подключитесь к системе с помощью SQL-клиента. На рисунке ниже показаны параметры JDBC-драйвера DTM в SQL-клиенте DBeaver. Параметры JDBC-драйвера . На рисунке ниже показаны параметры подключения к системе с использованием драйвера DTM. Параметры подключения к системе . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Подключение/Подключение_с_помощью_SQL-клиента/Подключение_с_помощью_SQL-клиента.html",
    "relUrl": "/Работа_с_системой/Подключение/Подключение_с_помощью_SQL-клиента/Подключение_с_помощью_SQL-клиента.html"
  },"35": {
    "doc": "Программное подключение",
    "title": "Программное подключение",
    "content": "Программное подключение . JDBC-драйвер системы позволяет подключаться программно (без использования SQL-клиента). Вы можете реализовать свое приложение, работающее с системой через JDBC-подключение. Чтобы подключиться к системе с помощью программного подключения: . | Загрузите скомпилированный файл драйвера с именем dtm-jdbc-&lt;version&gt;.jar. | Определите путь к jar-файлу драйвера любым из способов: . | задайте путь с помощью переменной окружения CLASSPATH; | задайте путь в командной строке при запуске своего приложения (формат зависит от операционной системы): java -classpath /&lt;path-to-driver&gt;/dtm-jdbc-&lt;version&gt;.jar myapplication.class . | . | В реализации класса вашего приложения, который отвечает за подключение к системе (см. пример ниже): . | импортируйте пакеты Java SQL: import java.sql.*; . | если используется Java версии менее 1.6, загрузите драйвер в память: Class.forName(\"io.arenadata.dtm.jdbc.DtmDriver\"); . | установите соединение с системой с помощью метода DriverManager.getConnection() в следующем формате: String url = \"jdbc:adtm://DtmHost:portNumber/logicalDatabaseName\"; Connection conn = DriverManager.getConnection(url, null, null); . | . | . Строка url содержит параметры: . | DtmHost — IP-адрес или имя хоста, на котором установлена система; | portNumber — номер порта для подключения; | (опционально) logicalDatabaseName — имя логической базы данных, используемой по умолчанию. | . Пример url: . String url = \"jdbc:adtm://10.92.3.3:9092/demo\"; Connection conn = DriverManager.getConnection(url, null, null); . После установки соединения можно выполнять запросы SQL . По окончании работы с системой нужно закрыть подключение. В примере ниже показана базовая реализация класса SimpleDtmJDBCExample, который устанавливает соединение с системой по заданному адресу и затем закрывает соединение. import java.sql.*; public class SimpleDtmJDBCExample { public static void main(String[] args) { Connection conn; String url = \"jdbc:adtm://10.92.3.3:9092/demo\"; try { conn = DriverManager.getConnection(url); System.out.println(\"Connected\"); } catch (SQLException e) { // Catch all for the SQL exceptions e.printStackTrace(); } finally { conn.close(); } } . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Подключение/Программное_подключение/Программное_подключение.html",
    "relUrl": "/Работа_с_системой/Подключение/Программное_подключение/Программное_подключение.html"
  },"36": {
    "doc": "Работа с системой",
    "title": "Работа с системой",
    "content": "Работа с системой . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Работа_с_системой.html",
    "relUrl": "/Работа_с_системой/Работа_с_системой.html"
  },"37": {
    "doc": "Запрос метаданных логической схемы",
    "title": "Запрос метаданных логической схемы",
    "content": "Запрос метаданных логической схемы . Чтобы запросить метаданные объектов логической схемы данных, выполните запрос SELECT FROM INFORMATION_SCHEMA (см. примеры ниже). Доступно получение информации о сущностях и их свойствах, перечисленных в разделе Системные представления (INFORMATION_SCHEMA). Примеры . Запрос списка всех логических БД окружения с лексической сортировкой по возрастанию: . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос информации о логических сущностях логической БД SALES: . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' . Запрос списка имен, типов и столбцов логических сущностей окружения: . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Запрос_метаданных_логической_схемы/Запрос_метаданных_логической_схемы.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Запрос_метаданных_логической_схемы/Запрос_метаданных_логической_схемы.html"
  },"38": {
    "doc": "Изменение логического представления",
    "title": "Изменение логического представления",
    "content": "Изменение логического представления . Чтобы изменить логическое представление в логической БД, выполните запрос ALTER VIEW или CREATE OR REPLACE VIEW (см. CREATE VIEW). При успешном выполнении запроса логическое представление изменит свой вид. Пример . -- выбор sales как логической базы данных по умолчанию USE sales -- создание логического представления CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 10 -- изменение логического представления ALTER VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 -- пересоздание логического представления CREATE OR REPLACE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Изменение_логического_представления/Изменение_логического_представления.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Изменение_логического_представления/Изменение_логического_представления.html"
  },"39": {
    "doc": "Создание внешней таблицы выгрузки",
    "title": "Создание внешней таблицы выгрузки",
    "content": "Создание внешней таблицы выгрузки . Чтобы создать внешнюю таблицу выгрузки в логической БД, выполните запрос CREATE DOWNLOAD EXTERNAL TABLE (см. пример ниже). При успешном выполнении запроса в логической схеме данных появляется новая внешняя таблица выгрузки. Проверить наличие внешней таблицы можно в дереве объектов SQL-клиента (см. рисунок ниже). Совет: для удобства разделения таблиц выгрузки и загрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_download или transactions_ext_upload). Примечание: внешняя таблица представляет собой декларацию приемника данных и формата выгрузки данных и не хранит сами данные. На рисунке ниже показан фрагмент дерева объектов SQL-клиента, которое содержит внешнюю таблицу выгрузки sales_ext_download. Внешняя таблица выгрузки в дереве объектов . Пример . -- выбор базы данных sales по умолчанию USE sales -- создание внешней таблицы выгрузки CREATE DOWNLOAD EXTERNAL TABLE sales.sales_ext_download ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Создание_внешней_таблицы_выгрузки/Создание_внешней_таблицы_выгрузки.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Создание_внешней_таблицы_выгрузки/Создание_внешней_таблицы_выгрузки.html"
  },"40": {
    "doc": "Создание внешней таблицы загрузки",
    "title": "Создание внешней таблицы загрузки",
    "content": "Создание внешней таблицы загрузки . Чтобы создать внешнюю таблицу загрузки в логической БД, выполните запрос CREATE UPLOAD EXTERNAL TABLE (см. пример ниже). При успешном выполнении запроса в логической схеме данных появляется новая внешняя таблица загрузки. Проверить наличие внешней таблицы можно в дереве объектов SQL-клиента (см. рисунок ниже). Совет: для удобства разделения таблиц загрузки и выгрузки рекомендуется задавать имя таблицы, указывающее на ее тип (например, transactions_ext_upload или transactions_ext_download). Примечание: внешняя таблица представляет собой декларацию источника данных и формата загрузки данных и не хранит сами данные. На рисунке ниже показан фрагмент дерева объектов SQL-клиента, которое содержит внешнюю таблицу загрузки sales_ext_upload. Внешняя таблица загрузки в дереве объектов . Пример . -- выбор базы данных sales по умолчанию USE sales -- создание внешней таблицы загрузки CREATE UPLOAD EXTERNAL TABLE sales_ext_upload ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Создание_внешней_таблицы_загрузки/Создание_внешней_таблицы_загрузки.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Создание_внешней_таблицы_загрузки/Создание_внешней_таблицы_загрузки.html"
  },"41": {
    "doc": "Создание логического представления",
    "title": "Создание логического представления",
    "content": "Создание логического представления . Логическое представление можно создать на основе данных одной или нескольких логических таблиц. Чтобы создать логическое представление в логической БД, выполните запрос CREATE VIEW (см. пример ниже). При успешном выполнении запроса в логической схеме данных появляется новое логическое представление. Чтобы проверить наличие логического представления, используйте любой из способов: . | выполните запрос метаданных логической схемы данных, | выполните запрос SELECT к логическому представлению, | проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). | . На рисунке ниже показан фрагмент дерева объектов SQL-клиента, которое содержит логическое представление stores_by_sold_products. Логическое представление в дереве объектов . Пример . -- выбор базы данных sales по умолчанию USE sales -- создание представления stores_by_sold_products CREATE VIEW stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_quantity FROM sales.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 30 -- проверка наличия логического представления stores_by_sold_products SELECT CASE WHEN count(*) &gt; 0 THEN 'представление существует' ELSE 'представления не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' AND table_name = 'STORES_BY_SOLD_PRODUCTS' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Создание_логического_представления/Создание_логического_представления.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Создание_логического_представления/Создание_логического_представления.html"
  },"42": {
    "doc": "Создание логической базы данных",
    "title": "Создание логической базы данных",
    "content": "Создание логической базы данных . Чтобы создать логическую базу данных, выполните запрос CREATE DATABASE (см. пример ниже). В случае успешного выполнения запроса в логической схеме данных появляется новая логическая база данных. Чтобы проверить наличие логической базы данных, используйте любой из способов: . | выполните запрос метаданных логической схемы данных, | проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). | . Совет: для удобства написания последующих запросов к этой логической базе данных ее можно выбрать в качестве используемой по умолчанию. На рисунке ниже показана логическая БД в дереве объектов SQL-клиента (см. рисунок ниже). Логическая БД в дереве объектов . Пример . -- создание логической базы данных sales CREATE DATABASE sales -- проверка наличия логической базы данных sales SELECT CASE WHEN count(*) &gt; 0 THEN 'БД существует' ELSE 'БД не существует' END FROM INFORMATION_SCHEMA.schemata WHERE schema_name = 'SALES' -- выбор логической базы данных sales в качестве базы данных по умолчанию USE SALES . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Создание_логической_базы_данных/Создание_логической_базы_данных.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Создание_логической_базы_данных/Создание_логической_базы_данных.html"
  },"43": {
    "doc": "Создание логической таблицы",
    "title": "Создание логической таблицы",
    "content": "Создание логической таблицы . Чтобы создать логическую таблицу в логической базе данных, выполните запрос CREATE TABLE (см. пример ниже). При успешном выполнении запроса в логической схеме данных появляется новая логическая таблица. Чтобы проверить наличие логической таблицы, используйте любой из способов: . | выполните запрос метаданных логической схемы данных, | выполните запрос SELECT к логической таблице, | проверьте дерево объектов в вашем SQL-клиенте (см. рисунок ниже). | . На рисунке ниже показан фрагмент дерева объектов, которое содержит логические таблицы sales и stores, в SQL-клиенте. Логические таблицы в дереве объектов . Пример . -- выбор базы данных sales по умолчанию USE sales -- создание таблицы sales CREATE TABLE sales ( identification_number INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (identification_number) ) DISTRIBUTED BY (identification_number) -- проверка наличия логической таблицы sales SELECT CASE WHEN count(*) &gt; 0 THEN 'таблица существует' ELSE 'таблицы не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' AND table_name = 'SALES' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Создание_логической_таблицы/Создание_логической_таблицы.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Создание_логической_таблицы/Создание_логической_таблицы.html"
  },"44": {
    "doc": "Удаление внешней таблицы выгрузки",
    "title": "Удаление внешней таблицы выгрузки",
    "content": "Удаление внешней таблицы выгрузки . Чтобы удалить внешнюю таблицу выгрузки, выполните запрос DROP DOWNLOAD EXTERNAL TABLE (см. пример ниже). При успешном выполнении запроса внешняя таблица выгрузки удаляется из логической схемы данных. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление внешней таблицы выгрузки DROP DOWNLOAD EXTERNAL TABLE sales_ext_download . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Удаление_внешней_таблицы_выгрузки/Удаление_внешней_таблицы_выгрузки.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Удаление_внешней_таблицы_выгрузки/Удаление_внешней_таблицы_выгрузки.html"
  },"45": {
    "doc": "Удаление внешней таблицы загрузки",
    "title": "Удаление внешней таблицы загрузки",
    "content": "Удаление внешней таблицы загрузки . Чтобы удалить внешнюю таблицу загрузки, выполните запрос DROP UPLOAD EXTERNAL TABLE (см. пример ниже). При успешном выполнении запроса внешняя таблица удаляется из логической схемы данных. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление внешней таблицы загрузки DROP UPLOAD EXTERNAL TABLE sales_ext_upload . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Удаление_внешней_таблицы_загрузки/Удаление_внешней_таблицы_загрузки.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Удаление_внешней_таблицы_загрузки/Удаление_внешней_таблицы_загрузки.html"
  },"46": {
    "doc": "Удаление логического представления",
    "title": "Удаление логического представления",
    "content": "Удаление логического представления . Чтобы удалить логическое представление из логической БД, выполните запрос DROP VIEW (см. пример ниже). При успешном выполнении запроса логическое представление удаляется из логической схемы данных. Удаление логического представления никак не отражается в хранилище. Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление представления stores_by_sold_products DROP VIEW stores_by_sold_products -- проверка наличия логического представления stores_by_sold_products SELECT CASE WHEN count(*) &gt; 0 THEN 'представление существует' ELSE 'представления не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' AND table_name = 'STORES_BY_SOLD_PRODUCTS' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Удаление_логического_представления/Удаление_логического_представления.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Удаление_логического_представления/Удаление_логического_представления.html"
  },"47": {
    "doc": "Удаление логической базы данных",
    "title": "Удаление логической базы данных",
    "content": "Удаление логической базы данных . Чтобы удалить логическую базу данных, выполните запрос DROP DATABASE (см. пример ниже). При успешном выполнении запроса все данные, связанные с логической БД, удаляются из хранилища, и все соответствующие логические сущности удаляются из схемы данных. Пример . -- удаление логической базы данных sales DROP DATABASE sales -- проверка наличия логической базы данных sales SELECT CASE WHEN count(*) &gt; 0 THEN 'БД существует' ELSE 'БД не существует' END FROM INFORMATION_SCHEMA.schemata WHERE schema_name = 'SALES' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Удаление_логической_базы_данных/Удаление_логической_базы_данных.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Удаление_логической_базы_данных/Удаление_логической_базы_данных.html"
  },"48": {
    "doc": "Удаление логической таблицы",
    "title": "Удаление логической таблицы",
    "content": "Удаление логической таблицы . Чтобы удалить логическую таблицу и ее данные, выполните запрос DROP TABLE (см. пример ниже). При успешном выполнении запроса все данные, связанные с логической таблицей, удаляются из указанных СУБД хранилища. Логическая таблица удаляется при удалении ее последнего месторасположения (см. секцию DATASOURCE_TYPE в разделе DROP TABLE). Пример . -- выбор базы данных sales по умолчанию USE sales -- удаление таблицы sales из СУБД ADQM DROP TABLE sales DATASOURCE_TYPE = 'adqm' -- проверка наличия логической таблицы sales SELECT CASE WHEN count(*) &gt; 0 THEN 'таблица существует' ELSE 'таблицы не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' AND table_name = 'SALES' -- удаление таблицы sales из оставшихся СУБД (ADB, ADG) DROP TABLE sales -- проверка наличия логической таблицы sales SELECT CASE WHEN count(*) &gt; 0 THEN 'таблица существует' ELSE 'таблицы не существует' END FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' AND table_name = 'SALES' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Удаление_логической_таблицы/Удаление_логической_таблицы.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Удаление_логической_таблицы/Удаление_логической_таблицы.html"
  },"49": {
    "doc": "Управление схемой данных",
    "title": "Управление схемой данных",
    "content": "Управление схемой данных . Система позволяет организовать структуру данных с помощью логической схемы данных. Доступны следующие действия по управлению логической схемой данных: . | Создание логической базы данных | Удаление логической базы данных | Создание логической таблицы | Удаление логической таблицы | Создание логического представления | Изменение логического представления | Удаление логического представления | Создание внешней таблицы загрузки | Удаление внешней таблицы загрузки | Создание внешней таблицы выгрузки | Удаление внешней таблицы выгрузки | Запрос метаданных логической схемы | . Запросы на обновление логической схемы данных обрабатываются в порядке, описанном в разделе Порядок обработки запросов на обновление логической схемы. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Работа_с_системой/Управление_схемой_данных/Управление_схемой_данных.html",
    "relUrl": "/Работа_с_системой/Управление_схемой_данных/Управление_схемой_данных.html"
  },"50": {
    "doc": "Ресурсы",
    "title": "Ресурсы",
    "content": "Ресурсы . github-репозиторий Prostore . Коннекторы . | github-репозиторий Kafka PXF connector | github-репозиторий Kafka Clickhouse connector | github-репозиторий Kafka Tarantool loader | github-репозиторий Kafka ADB connector . | github-репозиторий Apache Avro fork | . | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Ресурсы/Ресурсы.html",
    "relUrl": "/Ресурсы/Ресурсы.html"
  },"51": {
    "doc": "ALTER VIEW",
    "title": "ALTER VIEW",
    "content": "ALTER VIEW . Запрос позволяет изменить вид логического представления в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Примечание: логическое представление можно также изменить с помощью запроса CREATE OR REPLACE VIEW (см. CREATE VIEW). Синтаксис . ALTER VIEW [db_name.]view_name AS SELECT query . Параметры . | db_name — имя логической базы данных, в которой находится логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя изменяемого логического представления; | query — SELECT-подзапрос, на основе которого строится новый вид логического представления. | . Ограничения . В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | директивы FOR SYSTEM_TIME, | секции DATASOURCE_TYPE. | . Пример . ALTER VIEW sales.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount ASC LIMIT 20 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/ALTER_VIEW/ALTER_VIEW.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/ALTER_VIEW/ALTER_VIEW.html"
  },"52": {
    "doc": "BEGIN DELTA",
    "title": "BEGIN DELTA",
    "content": "BEGIN DELTA . Запрос позволяет открыть новую горячую дельту для последующей загрузки данных. Номер открываемой дельты может быть указан в запросе или установлен системой. Примечание: перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о номере открытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса открывается новая дельта. Дельта получает номер, указанный в запросе (если номер указан и корректен) или определенный системой (если номер не указан). Дельта всегда открывается с номером, следующим по порядку за номером последней закрытой дельты. После успешного выполнения запроса можно выполнять запросы INSERT INTO logical_table на загрузку данных. Подробнее о порядке выполнения запросов для загрузки данных см. в разделе Загрузка данных. Если нужно отменить все изменения данных, загруженные в рамках открытой дельты, выполните запрос ROLLBACK DELTA. Синтаксис . Открытие новой дельты: . BEGIN DELTA . Открытие новой дельты с указанным номером: . BEGIN DELTA SET delta_number . Параметры . | delta_number — целочисленный номер открываемой дельты, равный номеру последней закрытой дельты 1. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK. | . Ограничения . Если в запросе указан номер открываемой дельты, он должен быть равен номеру последней закрытой дельты 1. Пример . BEGIN DELTA SET 10 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/BEGIN_DELTA/BEGIN_DELTA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/BEGIN_DELTA/BEGIN_DELTA.html"
  },"53": {
    "doc": "CHECK_DATA",
    "title": "CHECK_DATA",
    "content": "CHECK_DATA . Запрос позволяет проверить идентичность данных логической таблицы, загруженных за определенный период во все СУБД хранилища. Идентичность проверяется по всем операциям записи таблицы, начиная с дельты, указанной в запросе, и заканчивая последней закрытой дельтой. Обе граничные дельты включаются в проверку. Алгоритм проверки зависит от параметров запроса: . | если столбцы указаны, по каждой операции записи в каждой из целевых СУБД рассчитывается контрольная сумма на основе значений этих столбцов и полученные суммы сравниваются между СУБД; | если столбцы не указаны, по каждой операции записи в каждой из целевых СУБД рассчитывается количество записей и полученные значения сравниваются между СУБД. | . Подробнее о порядке проверки данных см. в секции Порядок проверки данных. Примеры запросов и ответов см. в секции Примеры. Примечание: в проверке участвуют целевые СУБД хранилища — те СУБД, в которых размещены данные проверяемой логической таблицы. Если такая СУБД одна, проверка все равно проходит и считается успешной (см. рисунок ниже). В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Если запрос выполнен успешно, ответ содержит сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Синтаксис . CHECK_DATA([db_name.]table_name, delta_number[, square-bracketed_column_list]) . Параметры . | db_name — имя логической базы данных, в которой находится проверяемая логическая таблица. Параметр опционален, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы; | delta_number — номер дельты, с которой начинается проверка. Должен быть меньше или равен номеру последней закрытой дельты. Номер последней закрытой дельты можно узнать с помощью запроса GET_DELTA_OK; | square_bracketed_column_list — список проверяемых столбцов таблицы. Элементы списка должны быть указаны в квадратных скобках через запятую, например [identification_number, transaction_date]. Если столбцы указаны, проверяется контрольная сумма записей по каждой операции записи во всех целевых СУБД хранилища, иначе — количество таких записей. | . Ограничения . | Разные наборы данных могут иметь одинаковую контрольную сумму, поэтому возможен ложноположительный результат проверки. | Количество записей в проверяемых операциях записи не должно превышать 4'294'967'298, иначе выдается исключение. | . Примеры . Запрос без перечисления столбцов . Проверка целостности данных логической таблицы stores75 в диапазоне [дельта 0, последняя закрытая дельта]: . CHECK_DATA(sales.stores75, 0) . На рисунке ниже показан пример ответа CHECK_DATA при успешной проверке логической таблицы stores75, данные которой размещены только в ADB. Ответ CHECK_DATA с проверкой только в ADB . Запрос с перечислением столбцов . Проверка целостности данных столбцов identification_number и transaction_date таблицы sales: . CHECK_DATA(sales.sales, 4, [identification_number, transaction_date]) . На рисунке ниже показан пример ответа на запрос CHECK_DATA по столбцам таблицы при наличии расхождений: контрольная сумма в ADB отличается от контрольной суммы в ADG и ADQM. Ответ CHECK_DATA с найденными расхождениями . Порядок проверки данных . Идентичность данных проверяется в следующем порядке: . | В каждой из целевых СУБД: . | Выбираются проверяемые дельты: от указанной в запросе до последней закрытой (обе включительно). | По каждой дельте выбираются все операции записи, совершенные в логической таблице, которая указана в запросе. | По каждой операции записи — в зависимости от параметров запроса — рассчитывается количество или контрольная сумма загруженных записей. Алгоритм расчета контрольной суммы см. ниже. | . | Значения по каждой операции записи сравниваются в целевых СУБД. | Если запрос обработан успешно, но хотя бы одно из значений отсутствует или не соответствует другим, в ответе возвращается сообщение о расхождениях в данных. Иначе возвращается сообщение об успешной проверке. | . Алгоритм расчета контрольной суммы . Контрольная сумма по операции записи рассчитывается по следующему алгоритму: . | По каждой записи, загруженной в логическую таблицу в операции записи, формируется текстовая строка: значения столбцов конвертируются в зависимости от типа данных (см. таблицу ниже) и записываются через точку с запятой. Значение NULL записывается как пустая строка. | Для полученной строки вычисляется MD5-хеш в виде байтовой последовательности в шестнадцатеричном формате. | Хеш интерпретируется как ASCII-строка в нижнем регистре. | Из строки выбираются первые 4 символа строки, выстраиваются в порядке от младшего к старшему (little endian) и конвертируются в целочисленную 32-битную контрольную сумму записи. | Контрольные суммы всех записей, загруженных в одной операции записи, суммируются — получается 64-битная контрольная сумма операции записи. | . В таблице ниже показано, как значения столбцов (column_value), указанных в запросе, конвертируются в зависимости от их типа данных. | Тип данных | Порядок конвертации | Пример | . | BOOLEAN | (column_value)::int | true -&gt; 1 | . | DATE | column_value - make_date(1970, 01, 01) | 2021-03-15 -&gt; 18701 | . | TIME | (extract(epoch from column_value)*1000000)::bigint | 13:01:44 -&gt; 46904000000 | . | TIMESTAMP | (extract(epoch from column_value)*1000000)::bigint | 2020-11-17 21:11:12 -&gt; 1605647472000000 | . | Другие типы данных | column_value | Иванов -&gt; Иванов | . Пример расчета контрольной суммы . Рассмотрим пример расчета контрольной суммы для одной записи таблицы sales со следующими значениями: . | identification_number = 10021, | transaction_date = 2020-11-17 21:11:12, | product_code = ABC1830. | . Контрольная сумма рассчитывается в следующем порядке: . | Формируется строка для хеш-функции: 10021;1605647472000000;ABC1830. | Вычисляется MD5-хеш: bedbead6aea8ca373d8f0a15713639c1. | Выбираются первые 4 символа хеша: bedb. | Символы интерпретируются как ASCII-строка в нижнем регистре: 98 101 100 98. | Строка конвертируется в целое 32-битное число: 98*20 101*28 100*216 98*224 = 1650746722. | . Контрольная сумма записи по рассмотренным столбцам равна 1650746722. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CHECK_DATA/CHECK_DATA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CHECK_DATA/CHECK_DATA.html"
  },"54": {
    "doc": "CHECK_DATABASE",
    "title": "CHECK_DATABASE",
    "content": "CHECK_DATABASE . Запрос позволяет проверить соответствие логических таблиц логической базы данных и их физических представлений — физических таблиц в хранилище данных. В проверке участвуют логические таблицы логической базы данных и все связанные с ними физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке логической таблицы. Проверяется соответствие следующих элементов: . | имен и порядка следования столбцов, | типов данных столбцов, | первичного ключа. | . Имена и порядок следования проверяются для всех столбцов логических и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . Проверка логической базы данных, выбранной по умолчанию: . CHECK_DATABASE() . Проверка указанной логической базы данных: . CHECK_DATABASE(db_name) . Параметры . | db_name — имя логической базы данных, для таблиц которой выполняется проверка. | . Примеры . Проверка логической базы данных sales: . CHECK_DATABASE(sales) . На рисунках ниже показаны примеры ответов: на первом — ответ при отсутствии расхождений, на втором — при наличии расхождений. Расхождения вызваны тем, что в целях иллюстрации между первым и вторым запросом столбец description одной из таблиц был переименован ADB. Ответ CHECK_DATABASE при успешной проверке . Ответ CHECK_DATABASE с найденными расхождениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CHECK_DATABASE/CHECK_DATABASE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CHECK_DATABASE/CHECK_DATABASE.html"
  },"55": {
    "doc": "CHECK_SUM",
    "title": "CHECK_SUM",
    "content": "CHECK_SUM . Запрос позволяет рассчитать контрольную сумму данных в указанной дельте. Дельта может быть любой: как закрытой, так и открытой (горячей). Расчет контрольной суммы возможен по следующим данным: . | отдельным столбцам логической таблицы, | всем столбцам логической таблицы, | всем логическим таблицам логической базы данных. | . Контрольная сумма рассчитывается для каждой целевой СУБД хранилища. Под целевыми СУБД подразумеваются СУБД, в которых размещены данные проверяемой логической таблицы или логической базы данных. Контрольная сумма рассчитывается пошагово: по логической таблице и затем, если требуется, по всей логической базе данных. Полученные значения сравниваются между целевыми СУБД. Если контрольные суммы на каком-либо из шагов не совпадают в разных СУБД, в ответе возвращается исключение Consistency breach detected for &lt;entity_name&gt;. Подробнее об алгоритмах расчета контрольных сумм см. ниже. В ответе возвращается: . | объект ResultSet с одной записью, содержащей контрольную сумму данных, при успешном выполнении запроса и отсутствии расхождений между СУБД хранилища; | исключение при наличии расхождений или неуспешном выполнении запроса. | . Примеры запросов и ответов см. в секции Примеры. Синтаксис . CHECK_SUM(delta_num[, [db_name.]table_name[, square-bracketed_column_list]]) . Параметры . | delta_num — номер открытой (горячей) или закрытой дельты, по которой рассчитывается контрольная сумма. Если других аргументов в запросе нет, контрольная сумма рассчитывается по всей логической БД; | table_name (опциональный) — имя логической таблицы, по которой рассчитывается контрольная сумма; | square-bracketed_column_list (опциональный) — список имен столбцов указанной логической таблицы, по которым рассчитывается контрольная сумма. Элементы списка перечисляются внутри квадратных скобок через запятую. Если список столбцов не указан, контрольная сумма рассчитывается по всем столбцам логической таблицы. | . Ограничения . | Разные наборы данных могут иметь одинаковую контрольную сумму. | Количество записей в проверяемых операциях записи не должно превышать 4'294'967'298, иначе выдается исключение. | . Примеры . Запрос по столбцам логической таблицы . Расчет контрольной суммы по трем столбцам таблицы sales в десятой дельте: . CHECK_SUM(10,sales.sales,[identification_number, transaction_date, product_code]) . На рисунках ниже показаны примеры ответов на запрос CHECK_SUM с перечислением столбцов: на первом — ответ при отсутствии расхождений в данных между СУБД хранилища, на втором — ответ при наличии расхождений. Ответ CHECK_SUM по указанным столбцам таблицы при отсутствии расхождений . Ответ CHECK_SUM при наличии расхождений . Запрос по логической таблице (всем столбцам таблицы) . Расчет контрольной суммы по всей таблице sales в десятой дельте: . CHECK_SUM(10,sales.sales) . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической таблице. Ответ CHECK_SUM по логической таблице . Запрос по логической базе данных . Расчет контрольной суммы по всей логической базе данных sales в десятой дельте: . USE sales CHECK_SUM(10) . На рисунке ниже показан пример ответа на запрос CHECK_SUM по логической базе данных. Ответ CHECK_SUM по логической базе данных . Алгоритмы расчета контрольных сумм . Расчет контрольной суммы по логической таблице . Контрольная сумма по логической таблице рассчитывается по следующему алгоритму: . | По каждой операции записи таблицы в указанной дельте рассчитывается контрольная сумма. Алгоритм расчета такой же, как описанный в разделе CHECK_DATA. | Контрольные суммы всех операций записи таблицы выстраиваются в порядке от самой последней к первой и записываются через точку с запятой. | Для полученной строки вычисляется MD5-хеш в виде байтовой последовательности в шестнадцатеричном формате. | Хеш интерпретируется как ASCII-строка в нижнем регистре. | Из строки выбираются первые 8 символов строки, выстраиваются в порядке от младшего к старшему (little endian) и конвертируются в целочисленную 64-битную контрольную сумму. | . Расчет контрольной суммы по логической базе данных . Контрольная сумма по логической базе данных рассчитывается по следующему алгоритму: . | Таблицы логической БД выстраиваются в алфавитном порядке. | По каждой таблице логической БД в указанной дельте рассчитывается контрольная сумма, как описано выше. | Контрольные суммы по таблицам записываются через точку с запятой. | Далее порядок расчета такой же, как для таблицы (см. пункты 3-5 выше). | . Пример расчета контрольной суммы по таблице . Рассмотрим пример расчета контрольной суммы по таблице sales в дельте, содержащей две операции записи. Для простоты примера по каждой из записей возьмем заранее рассчитанную 32-битную контрольную сумму: 1650746722 (см. пример расчета в разделе CHECK_DATA) и 808792881. Контрольная сумма рассчитывается в следующем порядке: . | Формируется строка для хеш-функции: 808792881;1650746722. | Вычисляется MD5-хеш: ee0a6e094e2badb9d7dc5c9d7bebb961. | Выбираются первые 8 символов хеша: 92832a11. | Символы интерпретируются как ASCII-строка в нижнем регистре: 57 50 56 51 50 97 49 49. | Строка конвертируется в целое 32-битное число: 57*20 50*28 56*216 51*224 50*232 97*240 49*248 49*256 = 3544721249952870969. | . Контрольная сумма записи по рассмотренной таблице равна 3544721249952870969. ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CHECK_SUM/CHECK_SUM.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CHECK_SUM/CHECK_SUM.html"
  },"56": {
    "doc": "CHECK_TABLE",
    "title": "CHECK_TABLE",
    "content": "CHECK_TABLE . Запрос позволяет проверить соответствие логической таблицы и ее физических представлений — физических таблиц в хранилище данных. В проверке участвуют указанная логическая таблица и все связанные с ней физические таблицы. Если СУБД хранилища не хранит данные логической таблицы, и, следовательно, не содержит связанные физические таблицы, она пропускается при проверке. Проверяется соответствие следующих элементов: . | имен и порядка следования столбцов, | типов данных столбцов, | первичного ключа. | . Имена и порядок следования проверяются для всех столбцов логической и физических таблиц, включая служебные столбцы, имеющиеся только у физических таблиц. Например, если служебный столбец sys_to удален из физической таблицы, в ответе вернется сообщение о расхождении. В ответе возвращается: . | объект ResultSet с одной записью, содержащей результаты проверки, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает сообщение об успешной проверке или найденных расхождениях, а также список проверенных СУБД хранилища. Примеры запросов и ответов см. в секции Примеры. Синтаксис . CHECK_TABLE([db_name.]table_name) . Параметры . | db_name — имя логической базы данных, которой принадлежит проверяемая логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя проверяемой логической таблицы. | . Примеры . Проверка логической таблицы sales.sales: . CHECK_TABLE(sales.sales) . На рисунках ниже показаны примеры ответов в случае успешной проверки: на первом рисунке — по таблице, данные которой размещены во всех СУБД хранилища, на втором — по таблице, данные которой размещены только в ADB. Ответ CHECK_TABLE при успешной проверке . Ответ CHECK_TABLE с проверкой только в ADB . На рисунке ниже показан пример ответа при наличии расхождений. Проверка прошла успешно для ADG и ADQM, а в ADB найдено несоответствие — столбец description отсутствует в одной из физических таблиц. Ответ CHECK_TABLE с найденными расхождениями . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CHECK_TABLE/CHECK_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CHECK_TABLE/CHECK_TABLE.html"
  },"57": {
    "doc": "CHECK_VERSIONS",
    "title": "CHECK_VERSIONS",
    "content": "CHECK_VERSIONS . Запрос позволяет получить информацию о версиях следующих программных компонентов: . | компонентов системы, | компонентов, с которыми работает система. | . В ответе возвращается: . | объект ResultSet с записями, содержащими информацию об именах и версиях компонентах, при успешном выполнении запроса (см. рисунок ниже); | исключение при неуспешном выполнении запроса. | . Ответ CHECK_VERSIONS . Синтаксис . CHECK_VERSIONS() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CHECK_VERSIONS/CHECK_VERSIONS.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CHECK_VERSIONS/CHECK_VERSIONS.html"
  },"58": {
    "doc": "COMMIT DELTA",
    "title": "COMMIT DELTA",
    "content": "COMMIT DELTA . Запрос позволяет закрыть открытую (горячую) дельту. Дата и время закрытия дельты могут быть указаны в запросе или установлены системой. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дате и времени закрытия дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса горячие записи дельты перемещаются в категорию актуальных, а зафиксированные ранее записи, которые больше не являются актуальными, — в категорию архивных. Дельта закрывается и становится недоступна для загрузки данных. Подробнее о порядке обновления записей см. в разделе Физическая таблица. В качестве даты и времени закрытия дельты устанавливаются дата и время, указанные в запросе (если они указаны и корректны) или определенные системой (если дата и время не указаны). Синтаксис . Закрытие открытой дельты: . COMMIT DELTA . Закрытие открытой дельты с указанными датой и временем закрытия: . COMMIT DELTA SET date_time_expression . Параметры . | date_time_expression — метка даты и времени вида 'YYYY-MM-DD HH:MM:SS'. | . Ограничения . Если в запросе указаны дата и время закрытия дельты, они должны быть больше, чем дата и время последней закрытой дельты. Дату и время последней закрытой дельты можно узнать, выполнив запрос GET_DELTA_OK. Пример . COMMIT DELTA SET '2021-03-21 09:29:54' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/COMMIT_DELTA/COMMIT_DELTA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/COMMIT_DELTA/COMMIT_DELTA.html"
  },"59": {
    "doc": "CONFIG_STORAGE_ADD",
    "title": "CONFIG_STORAGE_ADD",
    "content": "CONFIG_STORAGE_ADD . Запрос позволяет подключить к системе источник данных — СУБД указанного типа. После успешного выполнения запроса можно создавать логические таблицы с размещением данных в этой СУБД и загружать данные в нее. Примечание: перед выполнением запроса необходимо добавить параметры СУБД в конфигурацию системы. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса все логические базы данных окружения активируются для указанной СУБД хранилища. При этом копирование логических таблиц и их данных из других СУБД хранилища не происходит и не может быть выполнено средствами системы. Синтаксис . CONFIG_STORAGE_ADD('datasource_alias') . Параметры . | datasource_alias — псевдоним СУБД хранилища. Возможные значения: adb, adqm, adg. | . Пример . Подключение ADB к хранилищу: . CONFIG_STORAGE_ADD('adb') . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CONFIG_STORAGE_ADD/CONFIG_STORAGE_ADD.html"
  },"60": {
    "doc": "CREATE DATABASE",
    "title": "CREATE DATABASE",
    "content": "CREATE DATABASE . Запрос позволяет создать логическую базу данных в текущем окружении. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно создавать логические таблицы, логические представления и внешние таблицы в созданной логической базе данных. Совет: перед наполнением созданной логической базы данных выберите ее в качестве используемой по умолчанию — это позволит не указывать имя логической БД перед именами логических сущностей в запросах к ней. Синтаксис . CREATE DATABASE db_name . Параметры . | db_name — имя создаваемой логической базы данных. Может содержать латинские буквы, цифры и символы подчеркивания (“_”). | . Пример . CREATE DATABASE sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CREATE_DATABASE/CREATE_DATABASE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CREATE_DATABASE/CREATE_DATABASE.html"
  },"61": {
    "doc": "CREATE DOWNLOAD EXTERNAL TABLE",
    "title": "CREATE DOWNLOAD EXTERNAL TABLE",
    "content": "CREATE DOWNLOAD EXTERNAL TABLE . Запрос позволяет создать внешнюю таблицу выгрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO download_external_table на выгрузку данных. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. Примечание: изменение внешней таблицы недоступно. Для замены некорректной внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION receiver_URI FORMAT 'AVRO' [CHUNK_SIZE records_per_message] . Параметры . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы выгрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_download; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | receiver_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | records_per_message — максимальное количество записей, выгружаемых из хранилища в одном сообщении топика Каfka. | . Пример . CREATE DOWNLOAD EXTERNAL TABLE sales.sales_ext_download ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales_out' FORMAT 'AVRO' CHUNK_SIZE 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CREATE_DOWNLOAD_EXTERNAL_TABLE/CREATE_DOWNLOAD_EXTERNAL_TABLE.html"
  },"62": {
    "doc": "CREATE TABLE",
    "title": "CREATE TABLE",
    "content": "CREATE TABLE . Запрос позволяет создать логическую таблицу в логической базе данных. В зависимости от параметров запроса данные логической таблицы размещаются в указанных или всех СУБД хранилища. Рекомендуется создавать логическую таблицу с размещением данных, как минимум, в СУБД, которая выбрана для выгрузки данных в конфигурации системы. Данные могут размещаться в любых СУБД хранилища, однако, если они размещаются вне СУБД выгрузки, их выгрузка недоступна. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса появляется новая таблица в логической схеме данных. Соответствующие физические таблицы появляются в СУБД хранилища, указанных в запросе, или, если СУБД не указаны в запросе, — во всех СУБД хранилища. Примечание: изменение логической таблицы недоступно. Для замены некорректной таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE TABLE [db_name.]table_name ( column_name_1 datatype_1 NOT NULL, column_name_2 datatype_2 DEFAULT default_value_2, column_name_3 datatype_3, PRIMARY KEY (column_list_1) ) DISTRIBUTED BY (column_list_2) DATASOURCE_TYPE (datasource_aliases) . Параметры . | db_name — имя логической базы данных, в которой создается логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя создаваемой логической таблицы, уникальное среди логических сущностей логической БД; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | default_value_N — значение столбца column_name_N по умолчанию; | column_list_1 — список столбцов, входящих в первичный ключ таблицы; | column_list_2 — список столбцов целочисленного типа, входящих в ключ шардирования таблицы. Столбцы должны быть из числа столбцов column_list_1; | datasource_aliases — список псевдонимов СУБД хранилища, в которых нужно разместить данные таблицы. Элементы списка перечисляются через запятую. Возможные значения: adb, adqm, adg. | . Ограничения . | Имена столбцов должны быть уникальны в рамках логической таблицы. | Недопустимо использование зарезервированных имен столбцов: sys_op, sys_from, sys_to, sys_close_date, bucket_id, sign. | Первичный ключ должен включать все столбцы ключа шардирования. | Ключ шардирования может содержать только целочисленные столбцы. | . Примеры . Создание логической таблицы с размещением данных во всех СУБД хранилища: . CREATE TABLE sales.sales ( identification_number INT NOT NULL, transaction_date TIMESTAMP NOT NULL, product_code VARCHAR(256) NOT NULL, product_units INT NOT NULL, store_id INT NOT NULL, description VARCHAR(256), PRIMARY KEY (identification_number) ) DISTRIBUTED BY (identification_number) . Создание логической таблицы с составным первичным ключом и размещением данных во всех СУБД хранилища: . CREATE TABLE sales.stores ( identification_number INT NOT NULL, category VARCHAR(256) NOT NULL, region VARCHAR(256) NOT NULL, address VARCHAR(256) NOT NULL, description VARCHAR(256), PRIMARY KEY (identification_number, region) ) DISTRIBUTED BY (identification_number) . Создание логической таблицы с размещением данных в ADQM и ADG (без размещения в ADB): . CREATE TABLE sales.clients ( identification_number INT NOT NULL, first_name VARCHAR(256) NOT NULL, last_name VARCHAR(256) NOT NULL, patronymic_name VARCHAR(256), birth_date DATE, PRIMARY KEY (identification_number) ) DISTRIBUTED BY (identification_number) DATASOURCE_TYPE (adqm,adg) . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CREATE_TABLE/CREATE_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CREATE_TABLE/CREATE_TABLE.html"
  },"63": {
    "doc": "CREATE UPLOAD EXTERNAL TABLE",
    "title": "CREATE UPLOAD EXTERNAL TABLE",
    "content": "CREATE UPLOAD EXTERNAL TABLE . Запрос позволяет создать внешнюю таблицу загрузки в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . После успешного выполнения запроса можно выполнять запросы INSERT INTO logical_table на загрузку данных. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. Примечание: изменение внешней таблицы недоступно. Для замены некорректной внешней таблицы необходимо удалить ее и создать новую. Синтаксис . CREATE UPLOAD EXTERNAL TABLE [db_name.]ext_table_name ( column_name_1 datatype_1, column_name_2 datatype_2, column_name_3 datatype_3 ) LOCATION source_URI FORMAT 'AVRO' [MESSAGE_LIMIT messages_per_segment] . Параметры . | db_name — имя логической базы данных, в которой создается внешняя таблица. Указание опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя создаваемой внешней таблицы загрузки. Для удобства различения таблиц выгрузки и таблиц загрузки рекомендуется задавать имя таблицы, указывающее на ее тип, например sales_ext_upload; | column_name_N — имя столбца таблицы; | datatype_N — тип данных столбца column_name_N. Возможные значения см. в разделе Логические типы данных; | source_URI — путь к топику Kafka (см. Формат пути к внешнему приемнику данных); | messages_per_segment — максимальное количество сообщений, загружаемых в хранилище в составе одного блока на один поток загрузки. Значение подбирается в зависимости от параметров производительности инфраструктуры. | . Пример . CREATE UPLOAD EXTERNAL TABLE sales.sales_ext_upload ( identification_number INT, transaction_date TIMESTAMP, product_code VARCHAR(256), product_units INT, store_id INT, description VARCHAR(256) ) LOCATION 'kafka://zk1:2181,zk2:2181,zk3:2181/sales' FORMAT 'AVRO' MESSAGE_LIMIT 1000 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CREATE_UPLOAD_EXTERNAL_TABLE/CREATE_UPLOAD_EXTERNAL_TABLE.html"
  },"64": {
    "doc": "CREATE VIEW",
    "title": "CREATE VIEW",
    "content": "CREATE VIEW . Запрос позволяет создать или заменить логическое представление в логической базе данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . Создание логического представления: . CREATE VIEW [db_name.]view_name AS SELECT query . Создание логического представления с заменой существующего представления, если такое будет найдено: . CREATE OR REPLACE VIEW [db_name.]view_name AS SELECT query . Параметры . | db_name — имя логической базы данных, в которой создается или заменяется логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя создаваемого или заменяемого логического представления. В запросе на создание представления имя должно быть уникально среди логических сущностей логической БД; | query — SELECT-подзапрос, на основе которого строится логическое представление. | . Ограничения . В подзапросе query не допускается использование: . | логических представлений, | системных представлений INFORMATION_SCHEMA, | директивы FOR SYSTEM_TIME, | секции DATASOURCE_TYPE. | . Пример . CREATE VIEW sales.stores_by_sold_products AS SELECT store_id, SUM(product_units) AS product_amount FROM sales.sales GROUP BY store_id ORDER BY product_amount DESC LIMIT 20 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/CREATE_VIEW/CREATE_VIEW.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/CREATE_VIEW/CREATE_VIEW.html"
  },"65": {
    "doc": "DROP DATABASE",
    "title": "DROP DATABASE",
    "content": "DROP DATABASE . Запрос позволяет удалить логическую базу данных и все ее данные. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении логическая база данных удаляется из логической схемы данных, и все связанные с ней данные удаляются из хранилища. Внимание: при удалении логической базы данных удаляются все ее данные и вся история изменений данных этой логической БД. Удаленные данные не подлежат восстановлению средствами системы. Синтаксис . DROP DATABASE db_name . Параметры . | db_name — имя удаляемой логической базы данных. | . Ограничения . Не допускается удаление системной базы данных с именем INFORMATION_SCHEMA. Пример . DROP DATABASE sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/DROP_DATABASE/DROP_DATABASE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/DROP_DATABASE/DROP_DATABASE.html"
  },"66": {
    "doc": "DROP DOWNLOAD EXTERNAL TABLE",
    "title": "DROP DOWNLOAD EXTERNAL TABLE",
    "content": "DROP DOWNLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу выгрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP DOWNLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных, из которой удаляется внешняя таблица выгрузки. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы выгрузки. | . Пример . DROP DOWNLOAD EXTERNAL TABLE sales.sales_ext_download . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/DROP_DOWNLOAD_EXTERNAL_TABLE/DROP_DOWNLOAD_EXTERNAL_TABLE.html"
  },"67": {
    "doc": "DROP TABLE",
    "title": "DROP TABLE",
    "content": "DROP TABLE . Запрос позволяет удалить логическую таблицу и ее данные из логической базы данных. В зависимости от параметров запроса данные таблицы удаляются из указанных или всех СУБД хранилища. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные логической таблицы удаляются из указанных СУБД хранилища. Логическая таблица удаляется из логической схемы данных при удалении данных из последней СУБД. Внимание: удаленные данные не подлежат восстановлению средствами системы. Удаление данных из СУБД, заданной для выгрузки в конфигурации системы, приведет к невозможности выгрузки этих данных. Синтаксис . DROP TABLE [IF EXISTS] [db_name.]table_name [DATASOURCE_TYPE = datasource_alias] . Опциональная секция IF EXISTS активирует проверку существования логической таблицы до попытки ее удаления. При наличии этой секции запрос по отсутствующей таблице возвращает успешный ответ. Параметры . | db_name — имя логической базы данных, из которой удаляется логическая таблица. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя удаляемой логической таблицы; | datasource_alias — псевдоним СУБД хранилища, из которой удаляются данные логической таблицы. Возможные значения: adb, adqm и adg. Значение можно указывать без кавычек, в одинарных кавычках (например, 'adb') или двойных кавычках (например, \"adb\"). Если секция DATASOURCE_TYPE с псевдонимом не указана, данные удаляются из всех СУБД хранилища. | . Примеры . Удаление логической таблицы с удалением данных из всех СУБД хранилища: . DROP TABLE sales.sales . Удаление логической таблицы с проверкой на ее существование: . DROP TABLE IF EXISTS sales.sales_unknown_existence . Последовательное удаление логической таблицы из ADB и ADG: . DROP TABLE sales.stores DATASOURCE_TYPE = adb DROP TABLE sales.stores DATASOURCE_TYPE = adg . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/DROP_TABLE/DROP_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/DROP_TABLE/DROP_TABLE.html"
  },"68": {
    "doc": "DROP UPLOAD EXTERNAL TABLE",
    "title": "DROP UPLOAD EXTERNAL TABLE",
    "content": "DROP UPLOAD EXTERNAL TABLE . Запрос позволяет удалить внешнюю таблицу загрузки из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . DROP UPLOAD EXTERNAL TABLE [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных, из которой удаляется внешняя таблица загрузки. Опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя удаляемой внешней таблицы загрузки. | . Пример . DROP UPLOAD EXTERNAL TABLE sales.sales_ext_upload . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/DROP_UPLOAD_EXTERNAL_TABLE/DROP_UPLOAD_EXTERNAL_TABLE.html"
  },"69": {
    "doc": "DROP VIEW",
    "title": "DROP VIEW",
    "content": "DROP VIEW . Запрос позволяет удалить логическое представление из логической базы данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса логическое представление удаляется из логической схемы данных. Синтаксис . DROP VIEW [db_name.]view_name . Параметры . | db_name — имя логической базы данных, из которой удаляется логическое представление. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | view_name — имя удаляемого логического представления. | . Пример . DROP VIEW sales.stores_by_sold_products . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/DROP_VIEW/DROP_VIEW.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/DROP_VIEW/DROP_VIEW.html"
  },"70": {
    "doc": "GET_DELTA_BY_DATETIME",
    "title": "GET_DELTA_BY_DATETIME",
    "content": "GET_DELTA_BY_DATETIME . Запрос позволяет получить информацию о последней закрытой дельте на указанные дату и время. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_DATETIME(date_time_expression) . Параметры . | date_time_expression — момент даты-времени вида 'YYYY-MM-DD HH:MM:SS'. | . Пример . GET_DELTA_BY_DATETIME('2021-03-25 07:30:32') . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/GET_DELTA_BY_DATETIME/GET_DELTA_BY_DATETIME.html"
  },"71": {
    "doc": "GET_DELTA_BY_NUM",
    "title": "GET_DELTA_BY_NUM",
    "content": "GET_DELTA_BY_NUM . Запрос позволяет получить информацию о закрытой дельте по ее номеру. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью, содержащей информацию о дельте, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия дельты, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_BY_NUM(delta_num) . Параметры . | delta_num — целый неотрицательный номер дельты. | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/GET_DELTA_BY_NUM/GET_DELTA_BY_NUM.html"
  },"72": {
    "doc": "GET_DELTA_HOT",
    "title": "GET_DELTA_HOT",
    "content": "GET_DELTA_HOT . Запрос позволяет получить информацию о горячей дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты; | [cn_from, cn_to] — диапазон порядковых номеров непрерывной последовательности операций записи, выполненных в рамках дельты; | cn_max — максимальный номер операции среди операций записи, выполненных в рамках дельты. До успешного завершения операций записи возвращается максимальный номер операции записи в последней закрытой дельте; | is_rolling_back — флаг отката; | write_op_finished — массив операций записей, выполненных в рамках дельты. | . В связи с многопоточной обработкой операций значения cn_to и cn_max горячей дельты могут отличаться. Например, если в рамках горячей дельты завершены операции записи с номерами 1, 2, 3 и 7, то значение cn_to этой дельты равно 3, а значение cn_max равно 7. Синтаксис . GET_DELTA_HOT() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/GET_DELTA_HOT/GET_DELTA_HOT.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/GET_DELTA_HOT/GET_DELTA_HOT.html"
  },"73": {
    "doc": "GET_DELTA_OK",
    "title": "GET_DELTA_OK",
    "content": "GET_DELTA_OK . Запрос позволяет получить информацию о последней закрытой дельте. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. В ответе возвращается: . | объект ResultSet c одной записью при успешном выполнении запроса. Если дельта присутствует, запись содержит информацию о дельте, иначе — возвращается пустая запись; | исключение при неуспешном выполнении запроса. | . Возвращаемая информация включает следующие параметры: . | delta_num — номер дельты, | delta_date — дата и время закрытия, | [cn_from, cn_to] — диапазон номеров выполненных операций записи. | . Синтаксис . GET_DELTA_OK() . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/GET_DELTA_OK/GET_DELTA_OK.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/GET_DELTA_OK/GET_DELTA_OK.html"
  },"74": {
    "doc": "INSERT INTO download_external_table",
    "title": "INSERT INTO download_external_table",
    "content": "INSERT INTO download_external_table . Запрос позволяет выгрузить данные, выбранные SELECT-подзапросом к логической базе данных, во внешний приемник данных. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на выгрузку данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные выгружаются из СУБД хранилища, выбранной для выгрузки в конфигурации системы. Данные выгружаются в том формате и в тот приемник данных, которые были указаны при создании внешней таблицы выгрузки. Формат данных соответствует описанному в разделе Формат выгрузки данных. Примечания: . | Перед выполнением запроса необходимо создать внешнюю таблицу с указанием пути к топику Kafka. Подробнее о порядке выполнения действий для выгрузки данных см. в разделе Выгрузка данных. | Имена и порядок следования столбцов должны совпадать в SELECT-подзапросе на выгрузку данных и внешней таблице выгрузки. | . Синтаксис . INSERT INTO [db_name.]ext_table_name SELECT ... Параметры . | db_name — имя логической базы данных, из которой выгружаются данные. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | ext_table_name — имя внешней таблицы выгрузки. | . Ограничения . | Секция DATASOURCE_TYPE игнорируется в SELECT-подзапросе. | Выгружаемые данные должны быть доступны в СУБД, выбранной для выгрузки в конфигурации системы. | . Пример . INSERT INTO sales.sales_ext_download SELECT * FROM sales.sales WHERE sales.product_units &gt; 2 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/INSERT_INTO_download_external_table/INSERT_INTO_download_external_table.html"
  },"75": {
    "doc": "INSERT INTO logical_table",
    "title": "INSERT INTO logical_table",
    "content": "INSERT INTO logical_table . Запрос позволяет загрузить данные в логическую таблицу логической базы данных из внешнего источника данных. Загружаемые данные должны соответствовать формату, указанному при создании внешней таблицы загрузки и описанному в разделе Формат загрузки данных. Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на загрузку данных. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса данные загружаются в СУБД хранилища, выбранные для размещения данных таблицы. Месторасположение данных таблицы можно задавать запросами CREATE TABLE и DROP TABLE. Примечания . | Перед выполнением запроса необходимо создать внешнюю таблицу, загрузить данные в топик Kafka и открыть дельту. Подробнее о порядке выполнения действий для загрузки данных см. в разделе Загрузка данных. | Имена и порядок следования столбцов должны совпадать в топике Kafka, внешней таблице загрузке и запросе на загрузку данных. Исключением является служебное поле sys_op, которое обязательно для топика и опционально для внешней таблицы, но должно отсутствовать в запросе на загрузку данных при явном перечислении столбцов. Подробнее о требованиях к загружаемым данным см. в разделе Формат загрузки данных. | . Синтаксис . Запрос с явным перечислением столбцов внешней таблицы: . INSERT INTO [db_name.]table_name SELECT column_list FROM [db_name.]ext_table_name . Запрос с использованием символа *: . INSERT INTO [db_name.]table_name SELECT * FROM [db_name.]ext_table_name . Параметры . | db_name — имя логической базы данных. Опционально, если выбрана логическая БД, используемая по умолчанию; | table_name — имя логической таблицы, в которую загружаются данные; | column_list — список имен столбцов внешней таблицы загрузки. Должен включать все имена столбцов логической таблицы. Если внешняя таблица содержит служебное поле sys_op, оно не указывается; | ext_table_name — имя внешней таблицы загрузки. | . Ограничения . Выполнение запроса возможно только при наличии открытой дельты (см. BEGIN DELTA). Пример . Пример загрузки данных с открытием и закрытием дельты: . BEGIN DELTA INSERT INTO sales.sales SELECT * FROM sales.sales_ext_upload COMMIT DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/INSERT_INTO_logical_table/INSERT_INTO_logical_table.html"
  },"76": {
    "doc": "ROLLBACK DELTA",
    "title": "ROLLBACK DELTA",
    "content": "ROLLBACK DELTA . Запрос позволяет откатить горячую дельту — вернуть логическую базу данных в состояние, которое предшествовало изменениям этой дельты. Перед выполнением запроса необходимо определить логическую базу данных, используемую по умолчанию, если она еще не определена. Если существуют незавершенные операции загрузки данных, то откат выполнить невозможно. При выполнении ROLLBACK все успешно завершенные операции откатятся. В ответе возвращается: . | объект ResultSet c одной записью, содержащей номер последней закрытой дельты, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса все изменения данных горячей дельты отменяются и зарезервированный ранее номер горячей дельты освобождается; номер последней закрытой дельты не изменяется. Примечание: откат закрытой дельты невозможен. Синтаксис . ROLLBACK DELTA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/ROLLBACK_DELTA/ROLLBACK_DELTA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/ROLLBACK_DELTA/ROLLBACK_DELTA.html"
  },"77": {
    "doc": "SELECT",
    "title": "SELECT",
    "content": "SELECT . Запрос позволяет выбрать данные из логических таблиц и представлений. Запрос можно использовать как самостоятельный запрос для чтения данных, а также в качестве подзапроса в запросах на выгрузку данных и запросах на создание и обновление логических представлений. Для выбора доступны следующие данные: . | актуальные данные; | архивные данные, которые были актуальны в указанный момент времени; | изменения данных, выполненные в рамках указанного диапазона дельт. | . Запрос обрабатывается в порядке, описанном в разделе Порядок обработки запросов на чтение данных. В ответе возвращается: . | объект ResultSet c выбранными записями при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . SELECT column_list FROM [db_name.]entity_name [FOR SYSTEM_TIME time_expression [AS alias_name]] [DATASOURCE_TYPE = 'datasource_alias'] . Описание параметров запроса см. ниже. В запросе можно использовать следующие секции, которые должны быть указаны в порядке их перечисления: . | FOR SYSTEM_TIME — для указания момента времени или периода, за который выбираются данные или изменения данных. Если секция не указана, данные выбираются по состоянию на дату и время обработки запроса; | JOIN ON — для соединения данных нескольких логических таблиц или представлений; | WHERE — для указания условий выбора данных; | GROUP BY — для группировки данных; | HAVING — для указания условий выбора сгруппированных данных; | ORDER BY — для сортировки данных; | LIMIT — для ограничения количества возвращаемых строк; | DATASOURCE_TYPE — для указания СУБД хранилища, из которой выбираются данные. | . Для имен таблиц, представлений и столбцов можно использовать псевдонимы. В запросе доступны оператор DISTINCT, агрегатные функции, а также соединение нескольких логических таблиц или логических представлений из одной или нескольких логических БД. Поддерживаются следующие типы соединений: . | [INNER] — внутреннее соединение, | NATURAL — внутреннее соединение по всем столбцам с одинаковыми именами, ключи соединения не указываются, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение таблиц или представлений, ключи соединения не указываются. | . Примечание: некоторые агрегатные функции и типы соединений недоступны для исполнения в определенных СУБД хранилища. Список доступных возможностей см. в разделе Поддержка SQL. Параметры . | column_list — список выбираемых столбцов таблицы или представления. Допустимо указывать символ * для выбора всех столбцов; | db_name — имя логической базы данных, из которой выбираются данные. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; | entity_name — имя таблицы или представления, из которого выбираются данные; | time_expression — выражение, которое задает момент или период времени, за который выбираются данные или изменения данных. Формат выражения см. ниже; | alias_name — псевдоним таблицы или представления. Может включать латинские буквы, цифры и символы подчеркивания; | datasource_alias — системный псевдоним СУБД хранилища, из которой выбираются данные. Возможные значения: adb, adqm, adg. | . Синтаксис директивы FOR SYSTEM_TIME . Директива FOR SYSTEM_TIME позволяет указать момент, по состоянию на который запрашиваются данные, или период (диапазон дельт), за который запрашиваются изменения. Директива относится к логической таблице или представлению, после имени которого она следует. Если в запросе соединяется несколько логических таблиц и представлений, для каждой логической сущности можно указать свою директиву, при этом значения директив могут различаться (см. пример ниже). Директива указывается в формате FOR SYSTEM_TIME time_expression, где выражение time_expression принимает одно из следующих значений: . | AS OF 'YYYY-MM-DD HH:MM:SS' — для запроса данных, актуальных на указанную дату и время; | AS OF DELTA_NUM delta_num — для запроса данных, актуальных на дату и время закрытия дельты с номером delta_num; | AS OF LATEST_UNCOMMITTED_DELTA — для запроса данных на текущий момент, включая данные, загруженные в рамках открытой (горячей) дельты. По горячей дельте возвращаются записи, загруженные в рамках непрерывного диапазона завершенных операций записи (см. параметры cn_from и cn_to в разделе GET_DELTA_HOT); | STARTED IN (delta_num1, delta_num2) — для запроса данных, добавленных или измененных в период между дельтой delta_num1 и дельтой delta_num2 (включительно); | FINISHED IN (delta_num1, delta_num2) — для запроса данных, удаленных в период между дельтой delta_num1 и дельтой delta_num2 (включительно). | . Ограничения . | Не допускается комбинирование подзапросов к логическим базам данных с подзапросами к системным представлениям INFORMATION_SCHEMA. | Если ключами секции JOIN выступают поля типа Nullable, то строки, где хотя бы один из ключей имеет значение NULL, не соединяются. | . Примеры . Запрос с неявным указанием столбцов и секцией WHERE: . SELECT * FROM sales.sales WHERE store_id = 1234 . Запрос с явным указанием столбцов и выбором данных из определенной СУБД хранилища (ADQM): . SELECT sold.store_id, sold.product_amount FROM sales.stores_by_sold_products AS sold DATASOURCE_TYPE = 'adqm' . Запрос с агрегацией, группировкой и сортировкой данных, а также выбором первых 20 строк: . SELECT s.store_id, SUM(s.product_units) AS product_amount FROM sales.sales AS s GROUP BY (s.store_id) ORDER BY product_amount DESC LIMIT 20 . Запрос записей, актуальных на момент закрытия дельты с номером 9: . SELECT * FROM sales.sales FOR SYSTEM_TIME AS OF DELTA_NUM 9 . Запрос с соединением данных двух логических таблиц из двух различных логических БД: . SELECT st.identification_number, st.category, s.product_code FROM sales.stores FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA AS st INNER JOIN sales2.sales FOR SYSTEM_TIME AS OF LATEST_UNCOMMITTED_DELTA AS s ON st.identification_number = s.store_id . Запрос с соединением записей логической таблицы, добавленных и измененных в двух различных диапазонах дельт: . -- выбор логической базы данных sales в качестве базы данных по умолчанию use sales -- запрос данных из логической таблицы prices SELECT p1.product_code, p1.price as feb_price, p2.price as march_price, (p2.price - p1.price) as diff FROM (SELECT product_code, price from sales.prices FOR SYSTEM_TIME STARTED IN(3,6)) AS p1 FULL JOIN (select product_code, price from sales.prices FOR SYSTEM_TIME STARTED IN(7,10)) AS p2 ON p1.product_code = p2.product_code WHERE p1.product_code is NOT NULL ORDER BY diff DESC LIMIT 50 DATASOURCE_TYPE = 'adb' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/SELECT/SELECT.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/SELECT/SELECT.html"
  },"78": {
    "doc": "SELECT FROM INFORMATION SCHEMA",
    "title": "SELECT FROM INFORMATION SCHEMA",
    "content": "SELECT FROM INFORMATION SCHEMA . Запрос позволяет получить метаданные объектов логической схемы, описанные в разделе Системные представления (INFORMATION_SCHEMA). Возможности запроса отличаются от возможностей SELECT-запроса к логическим базам данных. В ответе возвращается: . | объект ResultSet c выбранными записями при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . SELECT column_list FROM [INFORMATION_SCHEMA.]system_view_name [AS alias_name] . Описание параметров запроса см. ниже. Префикс INFORMATION_SCHEMA перед именем системного представления опционален, если до этого был выполнен запрос USE INFORMATION_SCHEMA. Для имен системных представлений и столбцов можно использовать псевдонимы. В запросе поддерживаются следующие секции, которые должны быть указаны в порядке их перечисления: . | JOIN ON — для соединения данных нескольких системных представлений; | WHERE — для указания условий выбора данных; | GROUP BY — для группировки данных; | ORDER BY — для сортировки данных; | LIMIT — для ограничения количества возвращаемых строк. | . Внимание: строковые значения столбцов в секции WHERE необходимо указывать в верхнем регистре (например, WHERE table_schema = 'SALES'). Поддерживаются следующие типы соединений системных представлений: . | [INNER] — внутреннее соединение, | LEFT [OUTER] — левое внешнее соединение, | RIGHT [OUTER] — правое внешнее соединение, | FULL [OUTER] — полное внешнее соединение, | CROSS — декартово произведение, ключи соединения не указываются. | . Параметры . | column_list — список выбираемых столбцов. Допустимо указывать символ * для выбора всех столбцов; | system_view_name — имя системного представления, из которого запрашивается информация. Возможные значения см. в разделе Системные представления (INFORMATION_SCHEMA); | alias_name — псевдоним системного представления. | . Ограничения . Не допускается комбинирование подзапросов к INFORMATION_SCHEMA с подзапросами к логическим базам данных. Примеры . Запрос списка всех логических БД окружения с лексической сортировкой по возрастанию: . SELECT schema_name FROM INFORMATION_SCHEMA.schemata ORDER BY schema_name . Запрос информации о логических сущностях логической БД SALES: . SELECT * FROM INFORMATION_SCHEMA.tables WHERE table_schema = 'SALES' . Запрос списка имен, типов и столбцов логических сущностей окружения: . SELECT TC.table_schema, TC.table_name, TT.table_type, TC.column_name FROM information_schema.columns AS TC JOIN information_schema.tables AS TT ON TC.table_schema = TT.table_schema and TC.table_name = TT.table_name ORDER BY TC.table_schema, TC.table_name . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/SELECT_FROM_INFORMATION_SCHEMA/SELECT_FROM_INFORMATION_SCHEMA.html"
  },"79": {
    "doc": "TRUNCATE HISTORY",
    "title": "TRUNCATE HISTORY",
    "content": "TRUNCATE HISTORY . Запрос позволяет удалить записи логической таблицы согласно заданным условиям. В зависимости от параметров запроса удаляются записи одной из категорий: . | записи таблицы, которые были перенесены в архив до указанного момента времени (включительно) и соответствуют условию, заданному в запросе; . | все архивные и актуальные записи таблицы, которые соответствуют условию, заданному в запросе. | . Если в запросе указан момент времени, система определяет дельту, которая являлась последней закрытой дельтой на тот момент, и удаляет все записи логической таблицы, которые стали архивными в эту дельту или ранее и соответствуют заданному условию. Иначе, если задано ключевое слово infinite, удаляются все записи таблицы, соответствующие условию. В ответе возвращается: . | пустой объект ResultSet при успешном выполнении запроса; . | исключение при неуспешном выполнении запроса. | . В результате успешного выполнения запроса записи, удовлетворяющие его параметрам, удаляются из логической таблицы. Внимание: удаленные данные не подлежат восстановлению средствами системы. На рисунке ниже показан пример работы запроса с указанным моментом времени. В примере логическая таблица содержит три записи об одном клиенте, загруженные в рамках трех разных дельт (дельта 0, дельта 1, дельта 2) в течение одного дня (2021-03-03). В результате исполнения запроса удаляется запись 0: на момент времени 18:00:00 дельта 1 была последней закрытой дельтой, и только запись 0 была архивной в эту дельту (запись 1 была актуальной). Удаление архивной записи по запросу с меткой времени . Синтаксис . TRUNCATE HISTORY [db_name.]table_name FOR SYSTEM_TIME AS OF date_time_expression [WHERE filter_expression] . Параметры . | db_name — имя логической базы данных. Указывается опционально, если выбрана логическая БД, используемая по умолчанию; . | table_name — имя логической таблицы, из которой удаляются записи; . | date_time_expression — выражение, определяющее категорию удаляемых записей. Может принимать следующие значения: . | 'YYYY-MM-DD HH:MM:SS' — удаление архивных записей по указанный момент времени; . | 'infinite' — удаление всех актуальных и архивных записей; . | . | filter_expression — условие выбора записей, подлежащих удалению. | . Пример . Удаление архивных записей таблицы sales, в которых значение столбца product_units меньше 10, по момент времени '2019-12-23 15:15:14': . TRUNCATE HISTORY sales.sales FOR SYSTEM_TIME AS OF '2019-12-23 15:15:14' WHERE product_units &lt; 10 . Удаление всех актуальных и архивных записей таблицы stores, в которых значение столбца identification_number равно 123456: . TRUNCATE HISTORY sales.stores FOR SYSTEM_TIME AS OF 'infinite' WHERE identification_number = 123456 . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/TRUNCATE_HISTORY/TRUNCATE_HISTORY.html"
  },"80": {
    "doc": "USE",
    "title": "USE",
    "content": "USE . Запрос позволяет изменить логическую базу данных по умолчанию на указанную логическую базу данных. Логическую базу данных по умолчанию необходимо определить перед выполнением запросов, предназначенных для управления дельтой и получения информации о ней. Это действие также можно выполнить перед другими запросами, что позволит не указывать имя логической БД перед именами логических сущностей в запросах к одной и той же логической базе данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя выбранной логической базы данных, при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . При успешном выполнении запроса указанная логическая база данных выбирается и используется по умолчанию до наступления первого из следующих событий: переключение на другую логическую БД с помощью запроса USE или закрытие соединения с системой. Примечание: альтернативно можно определить логическую базу данных по умолчанию в настройках JDBC-подключения (см. Определение логической БД по умолчанию). Синтаксис . USE db_name . Параметры . | db_name — имя логической базы данных, подлежащей установке по умолчанию. | . Пример . USE sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/USE/USE.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/USE/USE.html"
  },"81": {
    "doc": "USE INFORMATION_SCHEMA",
    "title": "USE INFORMATION_SCHEMA",
    "content": "USE INFORMATION_SCHEMA . Запрос позволяет изменить логическую базу данных по умолчанию на сервисную базу данных. Совет: запрос можно выполнить перед запросами SELECT FROM INFORMATION_SCHEMA — это даст возможность не указывать префикс INFORMATION_SCHEMA перед именами системных представлений в запросах к сервисной базе данных. В ответе возвращается: . | объект ResultSet c одной записью, содержащей имя сервисной базы данных (information_schema), при успешном выполнении запроса; | исключение при неуспешном выполнении запроса. | . Синтаксис . USE INFORMATION_SCHEMA . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/USE_INFORMATION_SCHEMA/USE_INFORMATION_SCHEMA.html"
  },"82": {
    "doc": "Запросы SQL+",
    "title": "Запросы SQL+",
    "content": "Запросы SQL . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Запросы_SQLplus/Запросы_SQLplus.html",
    "relUrl": "/Справочная_информация/Запросы_SQLplus/Запросы_SQLplus.html"
  },"83": {
    "doc": "Выгружаемые типы данных",
    "title": "Выгружаемые типы данных",
    "content": "Выгружаемые типы данных . Типы данных Avro, выгружаемые из системы, зависят от СУБД хранилища, из которой выгружаются данные. В таблице ниже для каждого логического типа данных указаны выгружаемые типы данных Avro. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Логический тип данных | Тип данных Avro, выгружаемый из ADB | Тип данных Avro, выгружаемый из ADG | Тип данных Avro, выгружаемый из ADQM | . | BOOLEAN | boolean | boolean | int | . | VARCHAR (n) | string | string | string | . | UUID | string | string | string | . | INT32 | int | int | int | . | INT | long | long | long | . | BIGINT | long | long | long | . | DOUBLE | double | double | double | . | FLOAT | float | float | float | . | DATE | int | int | int | . | TIME (precision) | long | long | long | . | TIMESTAMP (precision) | long | long | long | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Поддерживаемые_типы_данных/Выгружаемые_типы_данных/Выгружаемые_типы_данных.html",
    "relUrl": "/Справочная_информация/Поддерживаемые_типы_данных/Выгружаемые_типы_данных/Выгружаемые_типы_данных.html"
  },"84": {
    "doc": "Загружаемые типы данных",
    "title": "Загружаемые типы данных",
    "content": "Загружаемые типы данных . Система поддерживает загрузку типов данных Avro, перечисленных в таблице ниже. Для каждого типа данных Avro указан соответствующий логический тип данных. Подробнее о типах данных Avro см. в официальной документации Apache Avro. | Загружаемый тип данных Avro | Логический тип данных | . | boolean | BOOLEAN | . | string | VARCHAR (n) | . | int | INT32 | . | long | BIGINT | . | float | FLOAT | . | double | DOUBLE | . | (int) date | DATE | . | (long) time-micros | TIME (precision) | . | (long) timestamp-micros | TIMESTAMP (precision) | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Поддерживаемые_типы_данных/Загружаемые_типы_данных/Загружаемые_типы_данных.html",
    "relUrl": "/Справочная_информация/Поддерживаемые_типы_данных/Загружаемые_типы_данных/Загружаемые_типы_данных.html"
  },"85": {
    "doc": "Логические типы данных",
    "title": "Логические типы данных",
    "content": "Логические типы данных . Система поддерживает логические типы данных, описанные в таблице ниже. Для каждого из них в таблице указаны соответствующие физические типы данных СУБД хранилища. Примечание: при работе с логическими базами данных и их объектами нужно указывать логические типы данных. Физические типы данных описаны в справочных целях. | Логический тип | Описание | Тип данных ADB | Тип данных ADG | Тип данных ADQM | . | BOOLEAN | Логический (булевый) тип | boolean | boolean | UInt8 | . | VARCHAR (n) | Строка ограниченной длины (n символов) | varchar (n) | string | String | . | LINK | Строка неограниченной длины. Предназначена для ссылочных полей | varchar | string | String | . | CHAR (n) | Строка ограниченной длины (n символов) | varchar (n) | string | String | . | UUID | Строка ограниченной длины (36 символов) | varchar (36) | string | String | . | BIGINT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -9223372036854775808 до 9223372036854775807 | bigint (int8) | integer | Int64 | . | INT | Целое число фиксированной длины со знаком, находящееся в диапазоне от -9223372036854775808 до 9223372036854775807 | bigint (int8) | integer | Int64 | . | INT32 | Целое число фиксированной длины со знаком, находящееся в диапазоне от -2147483648 до 2147483647 | integer (int4) | integer | Int32 | . | DOUBLE | Число с плавающей запятой с двойной точностью | double (float8) | number | Float64 | . | FLOAT | Число с плавающей запятой | real (float4) | number | Float32 | . | DATE | Дата (без времени суток) | date | integer (знаковое число дней относительно даты 1970-01-01) | Int64 (знаковое число дней относительно даты 1970-01-01) | . | TIME, TIME (precision) | Время (без даты). Заданная точность (precision) влияет только на отображение времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6 | time (6) | integer (знаковое число микросекунд, начиная с 00:00:00.000000) | Int64 (знаковое число микросекунд, начиная с 00:00:00.000000) | . | TIMESTAMP, TIMESTAMP (precision) | Дата и время. Заданная точность (precision) влияет только на отображение даты и времени. Возможные значения: от 0 до 6. Значение 0 соответствует секундам, значение 6 — микросекундам. Значение по умолчанию — 6 | timestamp (6) | integer (знаковое число микросекунд относительно 1970-01-01 00:00:00) | Int64 (знаковое число микросекунд относительно 1970-01-01 00:00:00) | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Поддерживаемые_типы_данных/Логические_типы_данных/Логические_типы_данных.html",
    "relUrl": "/Справочная_информация/Поддерживаемые_типы_данных/Логические_типы_данных/Логические_типы_данных.html"
  },"86": {
    "doc": "Поддерживаемые типы данных",
    "title": "Поддерживаемые типы данных",
    "content": "Поддерживаемые типы данных . В разделе описаны следующие типы данных: . | логические типы данных системы и соответствующие им физические типы данных СУБД хранилища (см. Логические типы данных); | загружаемые типы данных Avro и соответствующие им логические типы данных (см. Загружаемые типы данных); | логические типы данных и соответствующие им выгружаемые типы данных Avro (см. Выгружаемые типы данных). | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Поддерживаемые_типы_данных/Поддерживаемые_типы_данных.html",
    "relUrl": "/Справочная_информация/Поддерживаемые_типы_данных/Поддерживаемые_типы_данных.html"
  },"87": {
    "doc": "Поддержка SQL",
    "title": "Поддержка SQL",
    "content": "Поддержка SQL . В SELECT-запросах к данным можно использовать функции, описанные в таблице ниже. СУБД хранилища имеют ограничения на использование некоторых функций в запросах, вызванные особенностями этих СУБД. Наиболее полный синтаксис запросов доступен в ADB. | Функция | Доступна в ADB | Доступна в ADQM | Доступна в ADG | . | ABS |   |   |   | . | ACOS |   |   | − | . | ASIN |   |   | − | . | ATAN |   |   | − | . | ATAN2 |   | − | − | . | AVG | − | − | − | . | BIT_AND |   | − | − | . | BIT_OR |   | − | − | . | CASE |   |   |   | . | CAST |   |   |   | . | CBRT |   | − | − | . | CEIL | аргумент FLOAT |   | − | . | CEILING | аргумент FLOAT |   | − | . | CHAR | − | − | − | . | COALESCE |   |   |   | . | COS |   |   | − | . | COUNT |   |   |   | . | CROSS JOIN |   | − |   | . | DEGREES |   | − | − | . | EXCEPT | − | − | − | . | EXP |   |   | − | . | FLOOR | аргумент FLOAT |   | − | . | FULL JOIN |   | − | − | . | GREATEST | − | − | − | . | HEX | − | − | − | . | IFNULL | − | − | − | . | INTERSECT | − | − | − | . | JOIN для трех таблиц |   | − |   | . | JOIN с подзапросом |   | − |   | . | LEAST | − | − | − | . | LENGTH | − | − | − | . | LIKELY | − | − | − | . | LN |   |   | − | . | LOG | − | − | − | . | LOWER |   |   |   | . | MAX |   |   |   | . | MIN |   |   |   | . | MOD |   | − | − | . | NULLIF |   |   |   | . | OCTET_LENGTH | − | − | − | . | PI | − | − | − | . | POSITION |   | − | − | . | POWER |   |   | − | . | PRINTF | − | − | − | . | QUOTE | − | − | − | . | RADIANS |   | − | − | . | RANDOM | − | − | − | . | REPLACE |   |   |   | . | RIGHT JOIN |   |   | − | . | ROUND | аргумент FLOAT |   | − | . | SIGN | аргумент FLOAT | − | − | . | SIN |   |   | − | . | SQRT |   |   | − | . | SUBSTRING |   |   | − | . | SUM |   |   |   | . | TAN |   |   | − | . | TRIM |   |   |   | . | TRUNC | − | − | − | . | TYPEOF | − | − | − | . | UNION | − | − | − | . | UPPER |   |   |   | . Примеры неподдерживаемых запросов . AVG . SELECT AVG(product_units) FROM sales.sales . CROSS JOIN . SELECT * FROM sales.sales AS s CROSS JOIN sales.stores AS st ORDER BY s.store_id, st.category LIMIT 5 DATASOURCE_TYPE = 'ADQM' . FULL JOIN . SELECT * FROM sales.sales AS s FULL JOIN sales.stores AS st ON s.store_id = st.identification_number ORDER BY s.store_id LIMIT 5 DATASOURCE_TYPE = 'ADG' . JOIN для трех таблиц . SELECT * FROM demo.territories AS t LEFT JOIN demo.employee_territories AS et ON t.territory_id = et.territory_id LEFT JOIN demo.employees AS e ON t.territory_id = e.territory_id WHERE e.last_name is NOT NULL ORDER BY t.territory_id DATASOURCE_TYPE = 'ADQM' . JOIN с подзапросом . SELECT * FROM sales.sales AS s INNER JOIN (SELECT * FROM sales.stores) AS st ON s.store_id = st.identification_number ORDER BY s.store_id DATASOURCE_TYPE = 'ADQM' . RIGHT JOIN . SELECT * FROM sales.sales AS s RIGHT JOIN sales.stores AS st ON s.store_id = st.identification_number ORDER BY st.identification_number LIMIT 5 DATASOURCE_TYPE = 'ADG' . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Поддержка_SQL/Поддержка_SQL.html",
    "relUrl": "/Справочная_информация/Поддержка_SQL/Поддержка_SQL.html"
  },"88": {
    "doc": "Системные представления (INFORMATION_SCHEMA)",
    "title": "Системные представления (INFORMATION_SCHEMA)",
    "content": "Системные представления (INFORMATION_SCHEMA) . Набор системных представлений (INFORMATION_SCHEMA) предоставляет доступ к метаданным логической схемы данных и содержит следующие элементы: . | schemata, | tables, | columns, | table_constraints, | key_column_usage. | . Набор системных представлений и их свойств фиксирован и недоступен для изменения. schemata . Системное представление schemata содержит список логических баз данных окружения. По каждой логической базе доступна следующая информация: . | catalog_name — наименование каталога, в который помещена логическая база данных. Значение по умолчанию — public; | schema_name — наименование логической базы данных. | . tables . Системное представление tables содержит список логических таблиц и представлений окружения. По каждой таблице или представлению доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления; | table_type — тип объекта. Возможные значения: BASE_TABLE — логическая таблица, VIEW — логическое представление. | . columns . Системное представление columns содержит список столбцов логических таблиц и представлений окружения. По каждому столбцу доступна следующая информация: . | table_catalog — наименование каталога, в который помещена таблица или представление. Значение по умолчанию — public; | table_schema — наименование логической базы данных, к которой относится таблица или представление; | table_name — наименование таблицы или представления, к которому относится столбец; | column_name — наименование столбца, по которому предоставлена информация; | is_nullable — признак того, может ли значение столбца иметь пустое значение (null). Возможные значения: YES — столбец может содержать пустое значение; NO — столбец должен содержать непустое значение; | ordinal_position — порядковый номер столбца в таблице или представлении (нумерация начинается с 1); | character_maximum_length — максимально допустимое количество символов (для строковых значений); | datetime_precision — степень отображаемой точности значений типа TIMESTAMP. Возможное значение: от 0 (точность до секунд) до 6 (точность до микросекунд). | data_type — тип данных столбца. Возможные значения см. в разделе Логические типы данных. | . table_constraints . Системное представление table_constraints содержит список ограничений логических таблиц и представлений окружения. По каждому ограничению доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | constraint_type — тип ограничения. Возможные значения: primary key — первичный ключ, sharding key — ключ шардирования. | . key_column_usage . Системное представление key_column_usage содержит список столбцов окружения, с которыми связаны какие-либо ограничения. По каждому столбцу доступна следующая информация: . | constraint_catalog — наименование каталога, в который помещена таблица или представление с ограничением. Значение по умолчанию — public; | constraint_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | constraint_name — наименование ограничения; | table_schema — наименование логической базы данных, к которой относится таблица или представление с ограничением; | table_name — наименование таблицы или представления, к которому относится ограничение; | column_name — наименование столбца, на который накладывается ограничение; | ordinal_position — порядковый номер поля в ключе (нумерация начинается с 1). | . Взаимосвязь системных представлений . На рисунке ниже показана взаимосвязь системных представлений. Взаимосвязь системных представлений . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Системные_представления_INFORMATION_SCHEMA/Системные_представления_INFORMATION_SCHEMA.html",
    "relUrl": "/Справочная_информация/Системные_представления_INFORMATION_SCHEMA/Системные_представления_INFORMATION_SCHEMA.html"
  },"89": {
    "doc": "Справочная информация",
    "title": "Справочная информация",
    "content": "Справочная информация . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Справочная_информация.html",
    "relUrl": "/Справочная_информация/Справочная_информация.html"
  },"90": {
    "doc": "Формат выгрузки данных",
    "title": "Формат выгрузки данных",
    "content": "Формат выгрузки данных . Сообщения имеют структуру, показанную на рисунке ниже. Структура выгружаемых сообщений . Данные выгружаются из системы в следующем формате: . | Выгрузка данных выполняется в топик Kafka, указанный в настройках внешней таблицы выгрузки. | Каждое сообщение топика Kafka состоит из ключа и тела. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных тела сообщения содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных из числа перечисленных в разделе Выгружаемые типы данных (см. пример ниже). | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). | Состав и порядок полей совпадают в следующих объектах: . | во внешней таблице выгрузки, | в схеме данных тела сообщения, | в наборе выгружаемых записей. | . | . Типы данных Avro, доступные к выгрузке из системы, описаны в разделе Выгружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример выгружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, выгружаемую с данными о продажах из СУБД ADB. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"row\", \"type\": \"record\", \"fields\": [ { \"name\": \"identification_number\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": \"string\" } ] } . Пример выгружаемых записей Avro . В примере ниже показан набор записей Avro о продажах, выгруженных из СУБД ADB и соответствующих схеме из предыдущего примера. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"identification_number\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1 1\" }, { \"identification_number\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\" } ] . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Формат_выгрузки_данных/Формат_выгрузки_данных.html",
    "relUrl": "/Справочная_информация/Формат_выгрузки_данных/Формат_выгрузки_данных.html"
  },"91": {
    "doc": "Формат загрузки данных",
    "title": "Формат загрузки данных",
    "content": "Формат загрузки данных . Данные загружаются в систему в виде сообщений топиков Kafka. Сообщения имеют структуру, показанную на рисунке ниже. Структура загружаемых сообщений . Для успешной загрузки данные должны соответствовать следующим условиям: . | Данные представлены в виде сообщений топика Kafka. | Каждое сообщение состоит из ключа и тела. Требования к ключу сообщения не предъявляются. | Тело сообщения представляет собой файл Avro (Object Container File), который состоит из заголовка и блоков данных. | Заголовок файла содержит схему данных Avro. | Схема данных содержит следующие элементы: имя, тип “record” и перечень полей. Для каждого поля указано имя, а также тип данных из числа перечисленных в разделе Загружаемые типы данных (см. пример ниже). Последним полем схемы указано служебное поле sys_op с типом данных int. | Каждый блок данных содержит запись, представленную в бинарной кодировке. Запись соответствует схеме данных из заголовка файла Avro. | Каждая запись содержит перечень полей и их значений. Имена и порядок перечисления полей, а также типы данных их значений соответствуют схеме данных (см. пример ниже). Последним полем каждой записи указано служебное поле sys_op со значением 0 (если запись добавляется или обновляется) или 1 (если запись удаляется). | Состав и порядок полей совпадают во всех следующих объектах: . | в схеме данных заголовка файла Avro, | в наборе загружаемых записей, | во внешней таблице загрузки (поле sys_op может отсутствовать, так как при создании внешней таблицы его можно не указывать), | в логической таблице, в которую загружаются данные (поле sys_op должно отсутствовать, так как оно относится к числу зарезервированных служебных полей). | . | . В схеме данных можно использовать логические типы Avro, а также элементы unions (см. пример ниже). Типы данных Avro, доступные к загрузке в систему, описаны в разделе Загружаемые типы данных. Подробнее о формате Avro см. в официальной документации на сайте https://avro.apache.org. Примеры . Пример загружаемой схемы данных Avro . Пример ниже содержит схему данных Avro, используемую для загрузки данных о продажах в логическую таблицу sales. Для поля transaction_date указан логический тип Avro, для поля description — элемент union. Для наглядности примера бинарные данные представлены в JSON-формате. { \"name\": \"sales\", \"type\": \"record\", \"fields\": [ { \"name\": \"identification_number\", \"type\": \"long\" }, { \"name\": \"transaction_date\", \"type\": \"long\", \"logicalType\": \"timestamp-micros\" }, { \"name\": \"product_code\", \"type\": \"string\" }, { \"name\": \"product_units\", \"type\": \"long\" }, { \"name\": \"store_id\", \"type\": \"long\" }, { \"name\": \"description\", \"type\": [ \"null\", \"string\" ] }, { \"name\": \"sys_op\", \"type\": \"int\" } ] } . Пример загружаемых записей Avro . Пример ниже содержит набор записей о продажах, загружаемых в логическую таблицу sales. Для наглядности примера бинарные данные представлены в JSON-формате. [ { \"identification_number\": 1000111, \"transaction_date\": 1614269474000000, \"product_code\": \"ABC102101\", \"product_units\": 2, \"store_id\": 1000012345, \"description\": \"Покупка по акции 1 1\", \"sys_op\": 0 }, { \"identification_number\": 1000112, \"transaction_date\": 1614334214000000, \"product_code\": \"ABC102001\", \"product_units\": 1, \"store_id\": 1000000123, \"description\": \"Покупка без акций\", \"sys_op\": 0 }, { \"identification_number\": 1000020, \"transaction_date\": 1614636614000000, \"product_code\": \"ABC102010\", \"product_units\": 4, \"store_id\": 1000000123, \"description\": \"Покупка по акции 1 1\", \"sys_op\": 1 } ] . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Формат_загрузки_данных/Формат_загрузки_данных.html",
    "relUrl": "/Справочная_информация/Формат_загрузки_данных/Формат_загрузки_данных.html"
  },"92": {
    "doc": "Формат пути к внешнему приемнику данных",
    "title": "Формат пути к внешнему приемнику данных",
    "content": "Формат пути к внешнему приемнику данных . При создании внешних таблиц загрузки и выгрузки данных необходимо указать путь (URI-строку) к внешнему приемнику данных, из которого извлекаются или в который помещаются данные. Для обоих типов внешних таблиц используется одинаковый формат URI-строки. Доступны следующие способы указания пути к топику Kafka, расположенному на узлах кластера Zookeeper: . | полный путь к топику, | путь к топику с использованием переменной, определенной в конфигурации системы. | . Указание полного пути к топику . Чтобы указать полный путь к топику Kafka, задайте URI-строку в следующем формате: . kafka://zkhost_1:port_1,zkhost_2:port_2,zkhost_3:port_3/chroot/path/topic_name . Где: . | zkhost_N (обязательный) — имя хоста или IP-адрес хоста Zookeeper, к которому подключен брокер сообщений Kafka; | port_N (обязательный) — порт хоста Zookeeper, к которому подключен брокер сообщений Kafka. Должен соответствовать порту, заданному в конфигурации Zookeeper для подключения клиентов (по умолчанию — 2181); | chroot/path — путь chroot к метаданным кластера Kafka. Следует использовать при наличии нескольких узлов Kafka в одном кластере Zookeeper; | topic_name (обязательный) — имя топика Kafka. | . Примеры . Имена нескольких хостов с непустым путем chroot (chroot_kafka): . kafka://zk1:2181,zk2:2181,zk3:2181/chroot_kafka/sales . IP-адрес одного хоста: . kafka://192.168.60.97:2181/chroot_kafka/sales . Указание пути к топику с использованием переменной . Чтобы указать путь к топику Kafka с использованием переменной конфигурации, задайте URI-строку в следующем формате: . kafka://$kafka/topic_name . Пример . Пример пути к топику sales: . kafka://$kafka/sales . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Справочная_информация/Формат_пути_к_внешнему_приемнику_данных/Формат_пути_к_внешнему_приемнику_данных.html",
    "relUrl": "/Справочная_информация/Формат_пути_к_внешнему_приемнику_данных/Формат_пути_к_внешнему_приемнику_данных.html"
  },"93": {
    "doc": "Конфигурация",
    "title": "Конфигурация",
    "content": "Конфигурация . Конфигурация системы задается в текстовом файле YAML-формата. Параметры конфигурации организованы в иерархическую структуру типа дерево. В разделе представлен примеры актуальных файлов конфигурации системы: конфигурации сервиса исполнения запросов и конфигурации сервиса мониторинга статусов Kafka. Перед каждым параметром указан комментарий, поясняющий назначение этого параметра. Для наглядности конфигурация сервиса исполнения запросов параметры разделена на отдельные секции. Конфигурация сервиса исполнения запросов . Настройки журналирования . # раздел настроек журналирования logging: # задание уровня важности сообщений, журналируемых в лог-файле level: io.arenadata.dtm.query.execution: TRACE . Настройки управления DTM . # раздел настроек управления DTM management: # номер порта сервиса метрик server: port: ${DTM_METRICS_PORT:8080} # настройки конечных точек ADTM endpoints: # настройка генерации метрик со стороны ADTM enabled-by-default: ${DTM_METRICS_ENABLED:true} # настройка видимости метрик через веб-соединения web: exposure: # состав метрик, видимых через веб-соединения include: ${DTM_METRICS_SCOPE:info, health, requests} . Настройки сервиса исполнения запросов . # раздел настроек сервиса исполнения запросов core: # настройки плагинов plugins: # список работающих плагинов к соответствующим СУБД active: ${CORE_PLUGINS_ACTIVE:ADG, ADB, ADQM} # настройки профилей приоритетности СУБД по категориям SQL-запросов category: mapping: # профиль для общих реляционных запросов RELATIONAL: ${DTM_CORE_PLUGINS_RELATIONAL:ADB, ADQM, ADG} # профиль для запросов аналитики ANALYTICAL: ${DTM_CORE_PLUGINS_ANALYTICAL:ADQM, ADB, ADG} # профиль для запросов ключ-значение DICTIONARY: ${DTM_CORE_PLUGINS_DICTIONARY:ADG, ADB, ADQM} # профиль для других категорий запросов UNDEFINED: ${DTM_CORE_PLUGINS_UNDEFINED:ADB, ADQM, ADG} # настройки сетевых подключений через HTTP-протокол http: # номер порта сервиса исполнения запросов port: ${DTM_CORE_HTTP_PORT:9090} # настройка режима оптимизации работы сокета TCP_NODELAY tcpNoDelay: ${DTM_CORE_HTTP_TCP_NO_DELAY:true} # настройка режима TCP FAST_OPEN tcpFastOpen: ${DTM_CORE_HTTP_TCP_FAST_OPEN:true} # настройка режима оптимизации работы сокета TCP_QUICKACK tcpQuickAck: ${DTM_CORE_HTTP_TCP_QUICK_ACK:true} # настройки окружения env: # имя окружения для формирования полных имен логических БД name: ${DTM_NAME:test} # настройки временной зоны settings: timeZone: ${CORE_TIME_ZONE:UTC} # настройки генерации метрики сервиса исполнения запросов metrics: isEnabled: ${DTM_CORE_METRICS_ENABLED:true} # настройки источника данных datasource: # настройки для EDML-операторов edml: # тип СУБД-источника (ADB, ADQM, ADG) sourceType: ${EDML_DATASOURCE:ADB} # количество записей, по умолчанию выгружаемых в одном сообщении топика Каfka defaultChunkSize: ${EDML_DEFAULT_CHUNK_SIZE:1000} # период проверки статуса плагина в миллисекундах pluginStatusCheckPeriodMs: ${EDML_STATUS_CHECK_PERIOD_MS:1000} # интервал времени ожидания (в миллисекундах) до тайм-аута при работе с первым смещением в топике Kafka firstOffsetTimeoutMs: ${EDML_FIRST_OFFSET_TIMEOUT_MS:15000} # интервал времени ожидания (в миллисекундах) до тайм-аута при ожидании смены смещения в топике Kafka changeOffsetTimeoutMs: ${EDML_CHANGE_OFFSET_TIMEOUT_MS:10000} # настройки Zookeeper zookeeper: # сетевой адрес хоста Zookeeper для служебной БД connection-string: ${ZOOKEEPER_DS_ADDRESS:10.92.3.47} # интервал времени ожидания (в миллисекундах) соединения с хостом Zookeeper для служебной БД до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_DS_CONNECTION_TIMEOUT_MS:30000} # интервал времени бездействия (в миллисекундах) в сессии хоста Zookeeper для служебной БД до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_DS_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для служебной БД chroot: ${ZOOKEEPER_DS_CHROOT:/adtm} # настройки взаимодействия сервиса исполнения запросов с брокером сообщений Kafka kafka: producer: property: # указание сериализатора строковых ключей key.serializer: org.apache.kafka.common.serialization.StringSerializer # указание сериализатора строковых значений value.serializer: org.apache.kafka.common.serialization.StringSerializer # настройка кластера Zookeeper для взаимодействия с брокером сообщений Kafka cluster: zookeeper: # сетевой адрес хоста Zookeeper для брокера сообщений Kafka connection-string: ${ZOOKEEPER_KAFKA_ADDRESS:10.92.3.47} # интервал времени ожидания (в миллисекундах) соединения с хостом Zookeeper для брокера сообщений Kafka до достижения тайм-аута connection-timeout-ms: ${ZOOKEEPER_KAFKA_CONNECTION_TIMEOUT_MS:30000} # интервал времени бездействия (в миллисекундах) в сессии хоста Zookeeper для брокера сообщений Kafka до достижения тайм-аута session-timeout-ms: ${ZOOKEEPER_KAFKA_SESSION_TIMEOUT_MS:86400000} # корневой путь к хосту Zookeeper для брокера сообщений Kafka chroot: ${ZOOKEEPER_KAFKA_CHROOT:} # настройки администратора Kafka admin: # интервал времени ожидания (в миллисекундах) входного потока данных для брокера сообщений Kafka до достижения тайм-аута inputStreamTimeoutMs: ${KAFKA_INPUT_STREAM_TIMEOUT_MS:2000} # настройки статусов публикации событий брокером сообщений Kafka status.event.publish: # разрешение на публикацию событий enabled: ${KAFKA_STATUS_EVENT_ENABLED:false} # наименование топика Kafka, в который публикуются события topic: ${KAFKA_STATUS_EVENT_TOPIC:status.event} # настройки подключения к сервису мониторинга статусов Kafka statusMonitor: # сетевой адрес и путь для получения информации о статусе сервиса statusUrl: ${STATUS_MONITOR_URL:http://127.0.0.1:9095/status} # сетевой адрес и путь для получения информации о версии сервиса versionUrl: ${STATUS_MONITOR_VERSION_URL:http://127.0.0.1:9095/versions} # настройки при использовании фреймворка vertx vertx: pool: # максимальный размер пула потоков, выполняющих долгие операции worker-pool: ${DTM_CORE_WORKER_POOL_SIZE:20} # максимальный размер пула потоков, обрабатывающих события vertx event-loop-pool: ${DTM_CORE_EVENT_LOOP_POOL_SIZE:20} # максимальный объем пула задач в сервисе исполнения запросов task-pool: ${DTM_CORE_TASK_POOL_SIZE:20} # интервал времени завершения задачи, выполняемой в сервисе исполнения запросов task-timeout: ${DTM_CORE_TASK_TIMEOUT:86400000} # настройки кэширования запросов cache: # начальная емкость кэша initialCapacity: ${CACHE_INITIAL_CAPACITY:100000} # максимальный размер кэша maximumSize: ${CACHE_MAXIMUM_SIZE:100000} # время (в минутах) устаревания кэша после последнего момента обращения к нему expireAfterAccessMinutes: ${CACHE_EXPIRE_AFTER_ACCESS_MINUTES:99960} . Настройки СУБД ADB . # настройка СУБД ADB adb: # настройка источника данных СУБД ADB datasource: # имя пользователя/логин для авторизации в СУБД ADB user: ${ADB_USERNAME:dtm} # пароль для авторизации в СУБД ADB password: ${ADB_PASS:dtm} # сетевой адрес хоста с СУБД ADB host: ${ADB_HOST:10.92.3.105} # сетевой адрес порта на хосте с СУБД ADB port: ${ADB_PORT:5432} # максимальный размер пула подключений к СУБД ADB poolSize: ${ADB_MAX_POOL_SIZE:5} # количество потоков, исполняющих запросы к СУБД ADB executorsCount: ${ADB_EXECUTORS_COUNT:20} # максимальный размер результата, возвращаемого по FETCH-запросу к СУБД ADB fetchSize: ${ADB_FETCH_SIZE:1000} # настройки механизма загрузки данных в СУБД ADB mppw: # наименование консьюмер-группы СУБД ADB для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADB_LOAD_GROUP:adb-emulator-load-adb} # максимальный размер пула подключений к СУБД ADB для операций загрузки poolSize: ${ADB_MPPW_POOL_SIZE:2} # значение тайм-аута ожидания (в миллисекундах) для остановки загрузки stopTimeoutMs: ${ADB_MPPW_STOP_TIMEOUT_MS:86400000} # предельное количество сообщений для операции загрузки в СУБД ADB defaultMessageLimit: ${ADB_MPPW_DEFAULT_MESSAGE_LIMIT:100} # значение тайм-аута ожидания (в миллисекундах) для FDW-коннектора ADB fdwTimeoutMs: ${ADB_MPPW_FDW_TIMEOUT_MS:1000} # признак использования исторических таблиц with-history-table: ${ADB_WITH_HISTORY_TABLE:false} . Настройки СУБД ADG . # настройка СУБД ADG adg: tarantool: db: # сетевой адрес хоста с СУБД ADG host: ${TARANTOOL_DB_HOST:10.92.3.120} # сетевой адрес порта на хосте с СУБД ADG port: ${TARANTOOL_DB_PORT:3306} # имя пользователя/логин для авторизации в СУБД ADG user: ${TARANTOOL_DB_USER:admin} # пароль для авторизации в СУБД ADG password: ${TARANTOOL_DB_PASS:memstorage-cluster-cookie} # максимальный интервал времени ожидания выполнения операции СУБД ADG до тайм-аута operationTimeout: ${TARANTOOL_DB_OPER_TIMEOUT:60000} # максимальное количество повторных попыток выполнения операции retryCount: ${TARANTOOL_DB_RETRY_COUNT:0} # движок СУБД ADG engine: ${TARANTOOL_DEFAULT_ENGINE:MEMTX} # настройки картриджа Tatantool cartridge: # сетевой путь и порт к картриджу Tarantool url: ${TARANTOOL_CATRIDGE_URL:http://10.92.3.120:8086} # настройки механизма загрузки данных mppw: # наименование консьюмер-группы СУБД ADG для взаимодействия с брокером сообщений Kafka consumerGroup: ${ADG_CONSUMER_GROUP:tarantool-group-csv} kafka: # максимальное количество сообщений в топике Kafka на раздел СУБД ADG maxNumberOfMessagesPerPartition: ${ADG_MAX_MSG_PER_PARTITION:200} # время простоя (в секундах) callback-функции callbackFunctionSecIdle: ${ADG_CB_FUNC_IDLE:100} # настройки отката операции rollback: # размер пакета операций при откате eraseOperationBatchSize: ${ADG_ROLLBACK_OPERATION_BATCH_SIZE:300} # настройки отказоустойчивости ADG по паттерну circuitbreaker circuitbreaker: # максимальное количество отказов ADG maxFailures: ${ADG_CIRCUIT_BREAKER_MAX_FAILURES:5} # интервал времени фиксации отказа при пропадании отклика ADG timeout: ${ADG_CIRCUIT_BREAKER_TIMEOUT:30000} # использование паттерна fallback при отказе fallbackOnFailure: ${ADG_CIRCUIT_BREAKER_FALLBACK_ON_FAILURE:false} # интервал времени до сброса по паттерну timeout resetTimeout: ${ADG_CIRCUIT_BREAKER_RESET_TIMEOUT:10000} # настройки для подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к СУБД ADG max-pool-size: ${ADG_WEB_CLIENT_MAX_POOL_SIZE:100} . Настройки СУБД ADQM . # настройки СУБД ADQM adqm: # настройка источника данных СУБД ADQM datasource: # наименование СУБД ADQM database: ${ADQM_DB_NAME:upload} # имя пользователя/логин для авторизации в СУБД ADQM user: ${ADQM_USERNAME:} # пароль для авторизации в СУБД ADQM password: ${ADQM_PASS:} # сетевой адрес хоста с СУБД ADQM и номер порта на хосте hosts: ${ADQM_HOSTS:10.92.3.30:8123} # интервал времени ожидания отклика соединения с СУБД ADQM до тайм-аута socketTimeout: ${ADQM_SOCKET_TIMEOUT:30000} # интервал времени ожидания завершения обмена данными с СУБД ADQM до тайм-аута dataTransferTimeout: ${ADQM_DATA_TRANSFER_TIMEOUT:10000} # настройки DDL-операторов ddl: # наименование кластера СУБД ADQM cluster: ${ADQM_CLUSTER:test_arenadata} # настройки механизма выгрузки данных из ADQM mppr: # сетевой адрес и путь для запросов на выгрузку данных loadingUrl: ${ADQM_MPPR_CONNECTOR_URL:http://10.92.3.14:8086/query} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPR_CONNECTOR_VERSION_URL:http://10.92.3.14:8086/versions} # настройки механизма загрузки данных ADQM mppw: # наименование консьюмер-группы СУБД ADQM для загрузки данных в СУБД ADQM # не используется consumerGroup: ${ADQM_CONSUMER_GROUP:adqm} # сетевой адрес брокера сообщений Kafka kafkaBrokers: ${ADQM_BROKERS:10.92.3.31:9092} # тип интерфейса для загрузки данных в СУБД ADQM loadType: ${ADQM_MPPW_LOAD_TYPE:REST} # сетевой адрес и путь к REST-интерфейсу для загрузки новых данных в СУБД ADQM restStartLoadUrl: ${ADQM_REST_START_LOAD_URL:http://10.92.3.86:8090/newdata/adqm/start} # сетевой адрес и путь к REST-интерфейсу для остановки загрузки данных в СУБД ADQM restStopLoadUrl: ${ADQM_REST_STOP_LOAD_URL:http://10.92.3.86:8090/newdata/adqm/stop} # сетевой адрес и путь для получения информации о версии коннектора versionUrl: ${ADQM_MPPW_CONNECTOR_VERSION_URL:http://10.92.3.86:8090/versions} # наименование коньсюмер-группы для загрузки данных в СУБД ADQM через REST API restLoadConsumerGroup: ${ADQM_REST_LOAD_GROUP:adb-emulator-load-adqm} # настройки для подключений веб-клиентов web-client: # максимальный размер пула подключений веб-клиентов к СУБД ADQM max-pool-size: ${ADQM_WEB_CLIENT_MAX_POOL_SIZE:100} . Конфигурация сервиса мониторинга статусов Kafka . # настройки cервиса мониторинга статусов Kafka monitor: # список адресов брокеров сообщений Kafka brokersList: ${STATUS_MONITOR_BROKERS:10.92.3.31:9092} # количество потребителей (консьюмеров) cервиса мониторинга Kafka consumersCount: ${STATUS_MONITOR_CONSUMERS:8} . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Эксплуатация/Конфигурация/Конфигурация.html",
    "relUrl": "/Эксплуатация/Конфигурация/Конфигурация.html"
  },"94": {
    "doc": "Минимальные системные требования",
    "title": "Минимальные системные требования",
    "content": "Минимальные системные требования . Система предъявляет следующие минимальные требования: . | аппаратные требования: . | ядро системы: 4 CPU, 16 RAM, 20 HDD; | сервис мониторинга статусов Kafka: 2 CPU, 8 RAM, 20 HDD; | . | программные требования: . | ADB версии 6.15.0; | ADQM версии 20.4.4.18; | ADG версии 2.7.2; | ADS: . | ADS версии 1.5; | Kafka версии 2.4; | Zookeeper версии 3.5.6. | . | . | . Компоненты, с которыми работает система, предъявляют минимальные требования, перечисленные в таблице ниже. | Компонент | Системные требования | . | ADB | https://docs.arenadata.io/adb/requirements/online.html#id2 | . | ADQM | https://docs.arenadata.io/adqm/requirements/index.html#clickhouse | . | ADG (Tarantool) | https://www.tarantool.io/en/sizing_calculator/ | . | Kafka | https://docs.arenadata.io/ads/Requirements/min.html | . | Zookeeper | https://docs.arenadata.io/ads/Requirements/min.html | . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Эксплуатация/Минимальные_системные_требования/Минимальные_системные_требования.html",
    "relUrl": "/Эксплуатация/Минимальные_системные_требования/Минимальные_системные_требования.html"
  },"95": {
    "doc": "Эксплуатация",
    "title": "Эксплуатация",
    "content": "Эксплуатация . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/Эксплуатация/Эксплуатация.html",
    "relUrl": "/Эксплуатация/Эксплуатация.html"
  },"96": {
    "doc": "Temporary folder for processing SVG-files",
    "title": "Temporary folder for processing SVG-files",
    "content": "Temporary folder for processing SVG-files . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/TMP/DRAWIO/",
    "relUrl": "/TMP/DRAWIO/"
  },"97": {
    "doc": "Temporary folder for processing XML-files",
    "title": "Temporary folder for processing XML-files",
    "content": "Temporary folder for processing XML-files . ",
    "url": "https://arenadata.github.io/docs_prostore_archive/v3-7-3/TMP/SVG/",
    "relUrl": "/TMP/SVG/"
  }
}
